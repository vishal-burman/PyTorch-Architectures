{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_sample_FastText.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOADLGhJTudQ4Q9lb9G+7SZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal-burman/PyTorch-Architectures/blob/master/modeling_FastText/test_sample_FastText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgtTMaagUQyY"
      },
      "source": [
        "! pip install transformers\r\n",
        "! pip install datasets\r\n",
        "! pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leN9UXW2T-Bk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baebe94b-8002-4471-d76b-89bf859284a3"
      },
      "source": [
        "# ! rm -rf PyTorch-Architectures/\r\n",
        "! git clone https://github.com/vishal-burman/PyTorch-Architectures.git\r\n",
        "%cd PyTorch-Architectures/modeling_FastText/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'PyTorch-Architectures' already exists and is not an empty directory.\n",
            "/content/PyTorch-Architectures/modeling_FastText\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqU0sw9-Yq-N"
      },
      "source": [
        "import time\r\n",
        "import random\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from model import FastText\r\n",
        "from transformers import BertTokenizer\r\n",
        "from datasets import load_dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FnJlbDUY0Ws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0828a6db-b0f4-47f0-c991-946b63db63a2"
      },
      "source": [
        "dataset = load_dataset(\"tweets_hate_speech_detection\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset tweets_hate_speech_detection (/root/.cache/huggingface/datasets/tweets_hate_speech_detection/default/0.0.0/c32a982d8b2d6233065d820ac655454174f8aaa8faddc74979cf793486acd3b0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o_OKMvYY5Up",
        "outputId": "63371c17-ed06-491f-8cbe-21957874f0db"
      },
      "source": [
        "sentences = []\r\n",
        "for sample in dataset['train']:\r\n",
        "  text = sample['tweet']\r\n",
        "  label = sample['label']\r\n",
        "  sentences.append({\r\n",
        "      'text': text,\r\n",
        "      'label': label,\r\n",
        "  })\r\n",
        "print('Length of total samples: ', len(sentences))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of total samples:  31962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnDspN8JY_2d"
      },
      "source": [
        "random.shuffle(sentences)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkvRJIyfu64W",
        "outputId": "0f458bac-29c6-4649-8674-3cb58060a7df"
      },
      "source": [
        "lim = 90 * len(sentences) // 100\r\n",
        "train_sentences = sentences[:lim]\r\n",
        "valid_sentences = sentences[lim:]\r\n",
        "\r\n",
        "print('Length of Train samples: ', len(train_sentences))\r\n",
        "print('Length of Valid samples: ', len(valid_sentences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Train samples:  28765\n",
            "Length of Valid samples:  3197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wgE1rr3uVqm"
      },
      "source": [
        "class CustomDataset(Dataset):\r\n",
        "  def __init__(self, tokenizer, list_samples, max_input_length=4):\r\n",
        "    self.tokenizer = tokenizer\r\n",
        "    self.list_samples = list_samples\r\n",
        "    self.max_input_length = max_input_length\r\n",
        "  \r\n",
        "  def __len__(self):\r\n",
        "    return len(self.list_samples)\r\n",
        "  \r\n",
        "  def __getitem__(self, idx):\r\n",
        "    samples = self.list_samples[idx]\r\n",
        "    texts = samples['text']\r\n",
        "    labels = samples['label']\r\n",
        "    tokens = self.tokenizer(texts, max_length=self.max_input_length, add_special_tokens=False, padding='max_length', truncation=True, return_tensors='pt')\r\n",
        "    input_ids = tokens['input_ids']\r\n",
        "    return {\r\n",
        "        'ids': input_ids,\r\n",
        "        'tgt': torch.tensor(labels),\r\n",
        "    }"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAQyBCu9w5Bh"
      },
      "source": [
        "# Define BERT tokenizer without special [PAD] or [CLS] token\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ2V7YrzxQU0"
      },
      "source": [
        "# Hyperparameters\r\n",
        "VOCAB_SIZE = tokenizer.vocab_size\r\n",
        "PAD_IDX = tokenizer.pad_token_id\r\n",
        "EMBEDDING_SIZE = 8\r\n",
        "HIDDEN_SIZE = 100\r\n",
        "OUTPUT_SIZE = 2\r\n",
        "MAX_INPUT_LENGTH = 8\r\n",
        "BATCH_SIZE = 32\r\n",
        "LEARNING_RATE = 0.001\r\n",
        "EPOCHS = 3"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf25kDnuxX5N",
        "outputId": "158ad94a-7404-421d-f25a-187af2330e56"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
        "model = FastText(vocab_size=VOCAB_SIZE, embedding_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE, output_size=OUTPUT_SIZE, padding_idx=PAD_IDX)\r\n",
        "model.to(device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FastText(\n",
              "  (embedding): Embedding(30522, 8, padding_idx=0)\n",
              "  (lin_1): Linear(in_features=8, out_features=100, bias=True)\n",
              "  (lin_2): Linear(in_features=100, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCotfboM5eeG",
        "outputId": "7a23c78c-37c6-4050-aa28-f7b512a97b26"
      },
      "source": [
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "print('Total Trainable Parameters: ', params)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Trainable Parameters:  245278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB6SgjYy5vVn",
        "outputId": "869eb964-be9d-4734-d7f1-6f7d25f0d051"
      },
      "source": [
        "train_dataset = CustomDataset(tokenizer, train_sentences, max_input_length=MAX_INPUT_LENGTH)\r\n",
        "valid_dataset = CustomDataset(tokenizer, valid_sentences, max_input_length=MAX_INPUT_LENGTH)\r\n",
        "\r\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\r\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\r\n",
        "\r\n",
        "print(\"Length of Training Loader: \", len(train_loader))\r\n",
        "print(\"Length of Valid Loader: \", len(valid_loader))\r\n",
        "\r\n",
        "# Sanity check loaders\r\n",
        "for sample in train_loader:\r\n",
        "  assert sample['ids'].squeeze(1).dim() == 2\r\n",
        "  assert sample['tgt'].size(0) == sample['ids'].size(0)\r\n",
        "  break"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Training Loader:  899\n",
            "Length of Valid Loader:  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyyRxOX55-ht"
      },
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE2ErwzR6LHI",
        "outputId": "65a52993-a93f-4377-beac-3c5ef8c89938"
      },
      "source": [
        "def compute_accuracy(model, data_loader, device):\r\n",
        "  correct_preds, total_examples = 0, 0\r\n",
        "  with torch.set_grad_enabled(False):\r\n",
        "    for sample in data_loader:\r\n",
        "      ids = sample['ids'].squeeze(1).to(device)\r\n",
        "      tgt = sample['tgt']\r\n",
        "      logits = model(ids)\r\n",
        "      probs = F.softmax(logits, dim=-1)\r\n",
        "      _, predicted_labels = torch.max(probs, 1)\r\n",
        "      correct_preds += (predicted_labels == tgt).sum()\r\n",
        "      total_examples += tgt.size(0)\r\n",
        "  return correct_preds / total_examples * 100 \r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  model.train()\r\n",
        "  for batch_idx, sample in enumerate(train_loader):\r\n",
        "    ids = sample['ids'].squeeze(1).to(device)\r\n",
        "    tgt = sample['tgt'].to(device)\r\n",
        "\r\n",
        "    logits = model(ids)\r\n",
        "    loss = F.cross_entropy(logits, tgt)\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    # LOGGING\r\n",
        "    if batch_idx % 200 == 0:\r\n",
        "      print('Batch: %04d/%04d || Epoch: %04d/%04d || Loss: %.2f' % (batch_idx, len(train_loader), epoch+1, EPOCHS, loss.item()))\r\n",
        "\r\n",
        "  model.eval()\r\n",
        "  with torch.set_grad_enabled(False):\r\n",
        "    train_accuracy = compute_accuracy(model, train_loader, device)\r\n",
        "    valid_accuracy = compute_accuracy(model, valid_loader, device)\r\n",
        "    print('Train Accuracy: %.2f%%' % (train_accuracy.item()))\r\n",
        "    print('Valid Accuracy: %.2f%%' % (valid_accuracy.item()))\r\n",
        "  epoch_elapsed_time = (time.time() - start_time) / 60\r\n",
        "  print('Epoch Elapsed Time: %.2f min' % (epoch_elapsed_time))\r\n",
        "total_training_time = (time.time() - start_time) / 60\r\n",
        "print('Total Training Time: %.2f min' % (total_training_time))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch: 0000/0899 || Epoch: 0001/0003 || Loss: 0.64\n",
            "Batch: 0200/0899 || Epoch: 0001/0003 || Loss: 0.15\n",
            "Batch: 0400/0899 || Epoch: 0001/0003 || Loss: 0.40\n",
            "Batch: 0600/0899 || Epoch: 0001/0003 || Loss: 0.16\n",
            "Batch: 0800/0899 || Epoch: 0001/0003 || Loss: 0.07\n",
            "Train Accuracy: 92.95%\n",
            "Valid Accuracy: 93.24%\n",
            "Epoch Elapsed Time: 0.66 min\n",
            "Batch: 0000/0899 || Epoch: 0002/0003 || Loss: 0.21\n",
            "Batch: 0200/0899 || Epoch: 0002/0003 || Loss: 0.06\n",
            "Batch: 0400/0899 || Epoch: 0002/0003 || Loss: 0.24\n",
            "Batch: 0600/0899 || Epoch: 0002/0003 || Loss: 0.11\n",
            "Batch: 0800/0899 || Epoch: 0002/0003 || Loss: 0.23\n",
            "Train Accuracy: 93.70%\n",
            "Valid Accuracy: 93.87%\n",
            "Epoch Elapsed Time: 1.30 min\n",
            "Batch: 0000/0899 || Epoch: 0003/0003 || Loss: 0.23\n",
            "Batch: 0200/0899 || Epoch: 0003/0003 || Loss: 0.07\n",
            "Batch: 0400/0899 || Epoch: 0003/0003 || Loss: 0.09\n",
            "Batch: 0600/0899 || Epoch: 0003/0003 || Loss: 0.03\n",
            "Batch: 0800/0899 || Epoch: 0003/0003 || Loss: 0.18\n",
            "Train Accuracy: 94.18%\n",
            "Valid Accuracy: 94.18%\n",
            "Epoch Elapsed Time: 1.94 min\n",
            "Total Training Time: 1.94 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtEYBVhE8dc6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}