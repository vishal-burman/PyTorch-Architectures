{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_sample_SSE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOh61xqT7FFUeaPqRCwJNR5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal-burman/PyTorch-Architectures/blob/master/modeling_SSE/test_sample_SSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJUP4UcSiHJo",
        "outputId": "954604f2-3f5f-4035-b201-4e34071e038a"
      },
      "source": [
        "! rm -rf PyTorch-Architectures/\r\n",
        "! git clone https://github.com/vishal-burman/PyTorch-Architectures.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorch-Architectures'...\n",
            "remote: Enumerating objects: 136, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 1074 (delta 63), reused 91 (delta 33), pack-reused 938\u001b[K\n",
            "Receiving objects: 100% (1074/1074), 8.48 MiB | 24.60 MiB/s, done.\n",
            "Resolving deltas: 100% (634/634), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FuVSnCkiUn_",
        "outputId": "97f37bc8-58a1-4f22-9f5c-cf17af9ef68e"
      },
      "source": [
        "%cd PyTorch-Architectures/modeling_SSE/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PyTorch-Architectures/modeling_SSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz3T57t5Rxc1"
      },
      "source": [
        "import time\n",
        "import pdb\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import Vectors, GloVe\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from model import BiLSTMSE\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLCIALsyShJY",
        "outputId": "af3bbc61-34c7-4708-c2fa-0f562813dccc"
      },
      "source": [
        "tokenize = lambda x: x.split()\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, include_lengths=True, batch_first=True, fix_length=200)\n",
        "LABEL = data.LabelField()\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "TEXT.build_vocab(train_data, vectors=GloVe(name='6B', dim=300))\n",
        "LABEL.build_vocab(train_data)\n",
        "word_embeddings = TEXT.vocab.vectors\n",
        "train_data, valid_data = train_data.split()\n",
        "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, valid_data, test_data), batch_size=32, sort_key=lambda x: len(x.text), repeat=False, shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 22.7MB/s]\n",
            ".vector_cache/glove.6B.zip: 862MB [06:28, 2.22MB/s]                           \n",
            "100%|█████████▉| 399427/400000 [00:36<00:00, 10696.95it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEMFv-su7-7r",
        "outputId": "9cb92ccc-9122-4895-b951-c7cd8ea01056"
      },
      "source": [
        "print('Length of Training Iterator: ', len(train_iter))\r\n",
        "print('Length of Valid Iterator: ', len(valid_iter))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Training Iterator:  547\n",
            "Length of Valid Iterator:  235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaH221Xpy4bd"
      },
      "source": [
        "# Parameters\r\n",
        "vocab_size = len(TEXT.vocab)\r\n",
        "emb_dim = 300\r\n",
        "hidden_dim = 300\r\n",
        "n_layers = 2\r\n",
        "natt_unit = 300\r\n",
        "natt_hops = 1\r\n",
        "nfc = 512\r\n",
        "n_class = 2\r\n",
        "drop_prob = 0.5\r\n",
        "penal_coeff = 0.1\r\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFzud3iamwF9"
      },
      "source": [
        "model = BiLSTMSE(\r\n",
        "    vocab_size=vocab_size,\r\n",
        "    emb_dim=emb_dim,\r\n",
        "    hidden_dim=hidden_dim,\r\n",
        "    n_layers=n_layers,\r\n",
        "    natt_unit=natt_unit,\r\n",
        "    natt_hops=natt_hops,\r\n",
        "    nfc=nfc,\r\n",
        "    n_class=n_class,\r\n",
        "    drop_prob=drop_prob,\r\n",
        "    weights=word_embeddings,\r\n",
        ")\r\n",
        "model = model.to(device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2E9u8VhumWr"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ke_I_YTr68i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98097873-2b6e-4c72-c61f-f72d26d98762"
      },
      "source": [
        "def loss_fn(x, y, model, penal_coeff, device):\r\n",
        "  pred, att = model(x)\r\n",
        "  loss = F.cross_entropy(pred, y)\r\n",
        "\r\n",
        "  # Penalty\r\n",
        "  div_penalty = (att @ att.transpose(1, 2)) - torch.eye(att.size(1)).to(device)\r\n",
        "  loss = loss + penal_coeff * torch.linalg.norm(div_penalty, dim=(1, 2))\r\n",
        "  loss = torch.mean(loss)\r\n",
        "  return pred, loss\r\n",
        "\r\n",
        "def compute_accuracy(model, data_loader, device):\r\n",
        "  correct_examples = 0\r\n",
        "  num_examples = 0\r\n",
        "  model.eval()\r\n",
        "  with torch.set_grad_enabled(False):\r\n",
        "    for idx, batch in enumerate(data_loader):\r\n",
        "      text = batch.text[0].to(device)\r\n",
        "      if text.size(0) is not 32:\r\n",
        "        continue\r\n",
        "      target = batch.label.to(device)\r\n",
        "      logits, _ = model(text)\r\n",
        "      logits = F.softmax(logits, dim=-1)\r\n",
        "      _, preds = torch.max(logits, 1)\r\n",
        "      correct_examples += (preds == target).sum()\r\n",
        "      num_examples += target.size(0)\r\n",
        "  return correct_examples.float() / num_examples * 100\r\n",
        "\r\n",
        "EPOCHS = 4\r\n",
        "start_time = time.time()\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  model.train()\r\n",
        "  for idx, batch in enumerate(train_iter):\r\n",
        "    text = batch.text[0].to(device)\r\n",
        "    label = batch.label.to(device)\r\n",
        "\r\n",
        "    if text.size(0) is not 32: # irregular behaviour in one batch\r\n",
        "      continue\r\n",
        "    \r\n",
        "    optimizer.zero_grad()\r\n",
        "    pred, loss = loss_fn(text, label, model, penal_coeff, device)\r\n",
        "    # LOGGING\r\n",
        "    if idx % 100 == 0:\r\n",
        "      # print('Loss: ', loss)\r\n",
        "      print('Batch: %04d/%04d || Epoch: %04d/%04d || Loss: %.2f' % (idx, len(train_iter), epoch+1, EPOCHS, loss))\r\n",
        "    loss.backward()\r\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\r\n",
        "    optimizer.step()\r\n",
        "  with torch.set_grad_enabled(False):\r\n",
        "    train_acc = compute_accuracy(model, train_iter, device)\r\n",
        "    valid_acc = compute_accuracy(model, valid_iter, device)\r\n",
        "    print('Training Accuracy: ', train_acc)\r\n",
        "    print('Valid Accuracy: ', valid_acc)\r\n",
        "  epoch_elapsed_time = (time.time() - start_time) / 60\r\n",
        "  print('Epoch Elapsed Time: ', epoch_elapsed_time)\r\n",
        "total_training_time = (time.time() - start_time) / 60\r\n",
        "print('Total Training Time: ', total_training_time)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch: 0000/0547 || Epoch: 0001/0004 || Loss: 0.80\n",
            "Batch: 0100/0547 || Epoch: 0001/0004 || Loss: 0.76\n",
            "Batch: 0200/0547 || Epoch: 0001/0004 || Loss: 0.60\n",
            "Batch: 0300/0547 || Epoch: 0001/0004 || Loss: 0.60\n",
            "Batch: 0400/0547 || Epoch: 0001/0004 || Loss: 0.70\n",
            "Batch: 0500/0547 || Epoch: 0001/0004 || Loss: 0.45\n",
            "Training Accuracy:  tensor(91.3290, device='cuda:0')\n",
            "Valid Accuracy:  tensor(83.3467, device='cuda:0')\n",
            "Epoch Elapsed Time:  1.2740498622258505\n",
            "Batch: 0000/0547 || Epoch: 0002/0004 || Loss: 0.34\n",
            "Batch: 0100/0547 || Epoch: 0002/0004 || Loss: 0.35\n",
            "Batch: 0200/0547 || Epoch: 0002/0004 || Loss: 0.38\n",
            "Batch: 0300/0547 || Epoch: 0002/0004 || Loss: 0.31\n",
            "Batch: 0400/0547 || Epoch: 0002/0004 || Loss: 0.30\n",
            "Batch: 0500/0547 || Epoch: 0002/0004 || Loss: 0.34\n",
            "Training Accuracy:  tensor(97.6648, device='cuda:0')\n",
            "Valid Accuracy:  tensor(84.0678, device='cuda:0')\n",
            "Epoch Elapsed Time:  2.5784456213315328\n",
            "Batch: 0000/0547 || Epoch: 0003/0004 || Loss: 0.20\n",
            "Batch: 0100/0547 || Epoch: 0003/0004 || Loss: 0.21\n",
            "Batch: 0200/0547 || Epoch: 0003/0004 || Loss: 0.21\n",
            "Batch: 0300/0547 || Epoch: 0003/0004 || Loss: 0.12\n",
            "Batch: 0400/0547 || Epoch: 0003/0004 || Loss: 0.48\n",
            "Batch: 0500/0547 || Epoch: 0003/0004 || Loss: 0.34\n",
            "Training Accuracy:  tensor(99.3876, device='cuda:0')\n",
            "Valid Accuracy:  tensor(84.0144, device='cuda:0')\n",
            "Epoch Elapsed Time:  3.8960808396339415\n",
            "Batch: 0000/0547 || Epoch: 0004/0004 || Loss: 0.10\n",
            "Batch: 0100/0547 || Epoch: 0004/0004 || Loss: 0.10\n",
            "Batch: 0200/0547 || Epoch: 0004/0004 || Loss: 0.28\n",
            "Batch: 0300/0547 || Epoch: 0004/0004 || Loss: 0.10\n",
            "Batch: 0400/0547 || Epoch: 0004/0004 || Loss: 0.10\n",
            "Batch: 0500/0547 || Epoch: 0004/0004 || Loss: 0.13\n",
            "Training Accuracy:  tensor(99.7997, device='cuda:0')\n",
            "Valid Accuracy:  tensor(83.6538, device='cuda:0')\n",
            "Epoch Elapsed Time:  5.22732892036438\n",
            "Total Training Time:  5.227333339055379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6QqYvtS6QVd",
        "outputId": "b49e35a9-2342-4044-858d-f855eff291d7"
      },
      "source": [
        "# Testing some sentences\r\n",
        "sentence_1 = \"This actor is boring and stupid\"\r\n",
        "sentence_1 = TEXT.preprocess(sentence_1)\r\n",
        "sentence_1 = [[TEXT.vocab.stoi[x] for x in sentence_1]]\r\n",
        "\r\n",
        "model.eval()\r\n",
        "with torch.set_grad_enabled(False):\r\n",
        "  sentence_1 = torch.tensor(sentence_1).to(device)\r\n",
        "  logits, att = model(sentence_1)\r\n",
        "  logits = F.softmax(logits, dim=-1)\r\n",
        "  _, preds = torch.max(logits, 1)\r\n",
        "  if preds.item() is 1:\r\n",
        "    print(\"Positive Sentiment\")\r\n",
        "  else:\r\n",
        "    print(\"Negative Sentiment\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative Sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "rjJEN7vtD9tU",
        "outputId": "dfd8af32-eb75-4bac-83ee-f9b5fa0e1353"
      },
      "source": [
        "# Visualizing the attention layer\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "np.squeeze(att.cpu().numpy(), 0).shape\r\n",
        "plt.figure(figsize=(8,1))\r\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\r\n",
        "sns.heatmap(np.squeeze(att.cpu().numpy(), 0), cmap=cmap, annot=True,\r\n",
        "            xticklabels=['This', 'actor', 'is', 'boring', 'and', 'stupid'], yticklabels=['att0'])\r\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x72 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxpP8tSlLLGk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}