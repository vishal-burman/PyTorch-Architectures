{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_sample_SSE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAq4AsWr6RQENyTJ2QGmlj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal-burman/PyTorch-Architectures/blob/master/modeling_SSE/test_sample_SSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJUP4UcSiHJo",
        "outputId": "94347a3d-77ef-4d35-e9b7-749c37d54b97"
      },
      "source": [
        "! git clone https://github.com/vishal-burman/PyTorch-Architectures.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorch-Architectures'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 1066 (delta 59), reused 88 (delta 32), pack-reused 938\u001b[K\n",
            "Receiving objects: 100% (1066/1066), 8.48 MiB | 20.10 MiB/s, done.\n",
            "Resolving deltas: 100% (630/630), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FuVSnCkiUn_",
        "outputId": "be3acb8a-687e-464d-c50e-6586a945f949"
      },
      "source": [
        "%cd PyTorch-Architectures/modeling_SSE/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PyTorch-Architectures/modeling_SSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz3T57t5Rxc1"
      },
      "source": [
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import Vectors, GloVe\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from model import BiLSTMSE\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLCIALsyShJY",
        "outputId": "088a146e-3fe1-4407-bd11-f3539a6b22d9"
      },
      "source": [
        "tokenize = lambda x: x.split()\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, include_lengths=True, batch_first=True, fix_length=200)\n",
        "LABEL = data.LabelField()\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "TEXT.build_vocab(train_data, vectors=GloVe(name='6B', dim=300))\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:05<00:00, 16.5MB/s]\n",
            ".vector_cache/glove.6B.zip: 862MB [06:27, 2.22MB/s]                           \n",
            "100%|█████████▉| 399245/400000 [00:45<00:00, 8397.48it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoIyMBOmSwNZ"
      },
      "source": [
        "word_embeddings = TEXT.vocab.vectors"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXQ7RE1CU4yP"
      },
      "source": [
        "train_data, valid_data = train_data.split()\n",
        "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, valid_data, test_data), batch_size=32, sort_key=lambda x: len(x.text), repeat=False, shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaH221Xpy4bd"
      },
      "source": [
        "# Parameters\r\n",
        "batch_size = 32\r\n",
        "vocab_size = len(TEXT.vocab)\r\n",
        "emb_dim = 300\r\n",
        "hidden_dim = 300\r\n",
        "n_layers = 2\r\n",
        "natt_unit = 300\r\n",
        "natt_hops = 1\r\n",
        "nfc = 512\r\n",
        "n_class = 2\r\n",
        "drop_prob = 0.5\r\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFzud3iamwF9"
      },
      "source": [
        "model = BiLSTMSE(\r\n",
        "    batch_size=batch_size,\r\n",
        "    vocab_size=vocab_size,\r\n",
        "    emb_dim=emb_dim,\r\n",
        "    hidden_dim=hidden_dim,\r\n",
        "    n_layers=n_layers,\r\n",
        "    natt_unit=natt_unit,\r\n",
        "    natt_hops=natt_hops,\r\n",
        "    nfc=nfc,\r\n",
        "    n_class=n_class,\r\n",
        "    drop_prob=drop_prob,\r\n",
        "    weights=word_embeddings,\r\n",
        ")\r\n",
        "model = model.to(device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2E9u8VhumWr"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ke_I_YTr68i"
      },
      "source": [
        "EPOCHS = 4\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  model.train()\r\n",
        "  for idx, batch in enumerate(train_iter):\r\n",
        "    text = batch.text[0].to(device)\r\n",
        "    label = batch.label.to(device)\r\n",
        "\r\n",
        "    if text.size(0) is not 32: # irregular behaviour in one batch\r\n",
        "      continue\r\n",
        "    \r\n",
        "    model = "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}