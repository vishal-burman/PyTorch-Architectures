{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_sample_DistilBERT_PT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcycyMGQ6peP+DOZq+g/ZO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal-burman/PyTorch-Architectures/blob/master/misc/test_sample_DistilBERT_PT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1WTDbnnfbqD"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spjl_2wnCACB"
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZV7okQICHfk"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VihmJQ3CQ_e"
      },
      "source": [
        "! mkdir ~/.kaggle\r\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9dKwT6MCdgi"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udsrrCHNCiAq"
      },
      "source": [
        "! kaggle datasets download -d datasnaek/mbti-type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrmKf6Yv1bsl",
        "outputId": "2501b38c-ab80-4866-a2d1-67d4d474cb4f"
      },
      "source": [
        "! unzip mbti-type.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  mbti-type.zip\n",
            "  inflating: mbti_1.csv              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRR-OzfLKgQl"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkPFLO1KCw-d"
      },
      "source": [
        "import time\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import random\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "\r\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Q3dOdEycGIcZ",
        "outputId": "8355d68b-6ebc-4ee9-c3ef-6bb845b65082"
      },
      "source": [
        "dataset = pd.read_csv('mbti_1.csv')\r\n",
        "dataset.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'You're fired.|||That's another silly misconce...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
              "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
              "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
              "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
              "4  ENTJ  'You're fired.|||That's another silly misconce..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRqJ2mg_DFIk"
      },
      "source": [
        "posts = dataset['posts']\r\n",
        "types = dataset['type']\r\n",
        "i_dataset = []\r\n",
        "e_dataset = []\r\n",
        "for type_p, post in zip(types, posts):\r\n",
        "  post = post.split('|||')\r\n",
        "  for text in post:\r\n",
        "    text = re.sub(r'http\\S+', '', text)\r\n",
        "    text = ' '.join(text.split()) # remove extra whitespaces from sentences\r\n",
        "    if len(text.split()) >= 3:\r\n",
        "      if \"I\" in type_p:\r\n",
        "        i_dataset.append((text.lower(), \"INTROVERT\"))\r\n",
        "      else:\r\n",
        "        e_dataset.append((text.lower(), \"EXTROVERT\"))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNJbyPaA5p0B",
        "outputId": "61ece0e0-0508-4faa-84bd-c29f5b6181d6"
      },
      "source": [
        "# The dataset is skewed towards introvert samples\r\n",
        "print(\"Original sample lengths:\")\r\n",
        "print(len(i_dataset), len(e_dataset))\r\n",
        "\r\n",
        "# Shuffling both introvert samples and extrovert samples\r\n",
        "random.shuffle(i_dataset)\r\n",
        "random.shuffle(e_dataset)\r\n",
        "\r\n",
        "# Taking min of both samples\r\n",
        "i_dataset = i_dataset[:min(len(i_dataset), len(e_dataset))]\r\n",
        "print('Reduced lengths:')\r\n",
        "print(len(i_dataset), len(e_dataset))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sample lengths:\n",
            "304390 92425\n",
            "Reduced lengths:\n",
            "92425 92425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rUwm4g8-Bek"
      },
      "source": [
        "final_dataset = []\r\n",
        "final_dataset.extend(i_dataset)\r\n",
        "final_dataset.extend(e_dataset)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VeY6oMEIhQj"
      },
      "source": [
        "# Shuffling final dataset\r\n",
        "random.shuffle(final_dataset)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBWPyFMBOSYT",
        "outputId": "4e3524c9-2178-40bf-f7a6-961b685ff6ac"
      },
      "source": [
        "limit = 90 * len(final_dataset) // 100\r\n",
        "train_list = final_dataset[:limit]\r\n",
        "valid_list = final_dataset[limit:]\r\n",
        "print('Length of train samples: ', len(train_list))\r\n",
        "print('Length of valid samples: ', len(valid_list))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train samples:  166365\n",
            "Length of valid samples:  18485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd-oOPRUKrAV",
        "outputId": "2347bfda-2252-4d95-94e5-1a9bc3141ccd"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\r\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\r\n",
        "model.to(device)\r\n",
        "\r\n",
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "print('Total trainable parameters: ', params)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total trainable parameters:  66955010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFNyAvN_Ii0t"
      },
      "source": [
        "class PersonalityDataset(Dataset):\r\n",
        "  def __init__(self, tokenizer, list_text, max_length=64):\r\n",
        "    self.tokenizer = tokenizer\r\n",
        "    self.list_text = list_text\r\n",
        "    self.max_length = max_length\r\n",
        "    self.samples = []\r\n",
        "    self.build()\r\n",
        "  \r\n",
        "  def __len__(self):\r\n",
        "    return len(self.samples)\r\n",
        "  \r\n",
        "  def __getitem__(self, idx):\r\n",
        "    tokens = self.samples[idx]['tokens']\r\n",
        "    target = self.samples[idx]['target']\r\n",
        "    input_ids = tokens['input_ids']\r\n",
        "    attention_mask = tokens['attention_mask']\r\n",
        "    return {\r\n",
        "        'ids': input_ids,\r\n",
        "        'mask': attention_mask,\r\n",
        "        'tgt': torch.tensor(target),\r\n",
        "    }\r\n",
        "\r\n",
        "  def build(self):\r\n",
        "    for sample in self.list_text:\r\n",
        "      text = sample[0]\r\n",
        "      p_type = 1 if sample[1] is \"INTROVERT\" else 0\r\n",
        "      tokens = self.tokenizer(text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors='pt')\r\n",
        "      self.samples.append({\r\n",
        "          'tokens': tokens,\r\n",
        "          'target': p_type,\r\n",
        "      })"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz1WQRs8MRgh"
      },
      "source": [
        "train_dataset = PersonalityDataset(tokenizer, train_list, max_length=64)\r\n",
        "valid_dataset = PersonalityDataset(tokenizer, valid_list, max_length=64)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6LSB8uGPOZI"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "LEARNING_RATE = 3e-5\r\n",
        "EPOCHS = 3"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5Gi0AdoSCvW",
        "outputId": "c8de2f3e-24bc-48e1-e342-bfa87c2de7ec"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\r\n",
        "valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\r\n",
        "\r\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\r\n",
        "\r\n",
        "# Check train loader\r\n",
        "for sample in train_loader:\r\n",
        "  ids = sample['ids']\r\n",
        "  mask = sample['mask']\r\n",
        "  tgt = sample['tgt'].unsqueeze(0)\r\n",
        "  print(ids.shape, mask.shape, tgt.shape)\r\n",
        "  break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1, 64]) torch.Size([128, 1, 64]) torch.Size([1, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3P_lbHoVJEZ",
        "outputId": "7cf438af-1259-4b5c-ce27-77f94156a728"
      },
      "source": [
        "print('Length of train_loader: ', len(train_loader))\r\n",
        "print('Length of valid_loader: ', len(valid_loader))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train_loader:  1300\n",
            "Length of valid_loader:  145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogKzFuh9SeOe",
        "outputId": "b62f52d8-f2ff-4a41-c0d9-d47f419813d6"
      },
      "source": [
        "def compute_accuracy(model, data_loader, device):\r\n",
        "  correct_pred, num_examples = 0, 0\r\n",
        "  for sample in data_loader:\r\n",
        "    ids = sample['ids'].squeeze(1).to(device)\r\n",
        "    mask = sample['mask'].squeeze(1).to(device)\r\n",
        "    tgt = sample['tgt'].unsqueeze(0).to(device)\r\n",
        "    outputs = model(input_ids=ids, attention_mask=mask)\r\n",
        "    logits = outputs.logits\r\n",
        "    probas = F.softmax(logits, dim=1)\r\n",
        "    _, predicted_labels = torch.max(probas, 1)\r\n",
        "    correct_pred += (predicted_labels == tgt).sum()\r\n",
        "    num_examples += tgt.size(1)\r\n",
        "  return correct_pred.float() / num_examples * 100\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  model.train()\r\n",
        "  for idx, sample in enumerate(train_loader):\r\n",
        "    ids = sample['ids'].squeeze(1).to(device)\r\n",
        "    mask = sample['mask'].squeeze(1).to(device)\r\n",
        "    tgt = sample['tgt'].unsqueeze(0).to(device)\r\n",
        "\r\n",
        "    outputs = model(input_ids=ids, attention_mask=mask, labels=tgt)\r\n",
        "    loss = outputs.loss\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    # LOGGING\r\n",
        "    if idx % 500 == 0:\r\n",
        "      print('Batch: %04d/%04d || Epoch: %04d/%04d || Loss: %.2f' % (idx, len(train_loader), epoch+1, EPOCHS, loss.item()))\r\n",
        "  \r\n",
        "  model.eval()\r\n",
        "  with torch.set_grad_enabled(False):\r\n",
        "    train_acc = compute_accuracy(model, train_loader, device)\r\n",
        "    valid_acc = compute_accuracy(model, valid_loader, device)\r\n",
        "    print('Train Accuracy: %.2f%%' % (train_acc))\r\n",
        "    print('Valid Accuracy: %.2f%%' % (valid_acc))\r\n",
        "  epoch_elapsed_time = (time.time() - start_time) / 60\r\n",
        "  print('Epoch Elapsed Time: %.2f min' % (epoch_elapsed_time))\r\n",
        "total_training_time = (time.time() - start_time) / 60\r\n",
        "print('Total Training Time: %.2f min' % (total_training_time))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch: 0000/1300 || Epoch: 0001/0003 || Loss: 0.69\n",
            "Batch: 0500/1300 || Epoch: 0001/0003 || Loss: 0.67\n",
            "Batch: 1000/1300 || Epoch: 0001/0003 || Loss: 0.65\n",
            "Train Accuracy: 64.05%\n",
            "Valid Accuracy: 60.84%\n",
            "Epoch Elapsed Time: 19.92 min\n",
            "Batch: 0000/1300 || Epoch: 0002/0003 || Loss: 0.67\n",
            "Batch: 0500/1300 || Epoch: 0002/0003 || Loss: 0.66\n",
            "Batch: 1000/1300 || Epoch: 0002/0003 || Loss: 0.60\n",
            "Train Accuracy: 70.94%\n",
            "Valid Accuracy: 61.31%\n",
            "Epoch Elapsed Time: 39.84 min\n",
            "Batch: 0000/1300 || Epoch: 0003/0003 || Loss: 0.56\n",
            "Batch: 0500/1300 || Epoch: 0003/0003 || Loss: 0.56\n",
            "Batch: 1000/1300 || Epoch: 0003/0003 || Loss: 0.53\n",
            "Train Accuracy: 81.86%\n",
            "Valid Accuracy: 60.60%\n",
            "Epoch Elapsed Time: 59.79 min\n",
            "Total Training Time: 59.79 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DppVgTlYX114",
        "outputId": "d66dd9c9-2ed5-480d-f155-1a8109820ba4"
      },
      "source": [
        "model.eval()\r\n",
        "with torch.set_grad_enabled(False):\r\n",
        "  text = \"I want to remain at home and play games\"\r\n",
        "  tokens = tokenizer(text, max_length=64, padding='max_length', truncation=True, return_tensors='pt')\r\n",
        "  outputs = model(input_ids=tokens['input_ids'].to(device), attention_mask=tokens['attention_mask'].to(device))\r\n",
        "  logits = outputs.logits\r\n",
        "  probas = F.softmax(logits, dim=1)\r\n",
        "  _, preds = torch.max(probas, 1)\r\n",
        "  print('Your input: ', text)\r\n",
        "  if preds.item() is 1:\r\n",
        "    print('Prediction --> Introvert')\r\n",
        "  else:\r\n",
        "    print('Prediction --> Extrovert')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your input:  I want to remain at home and play games\n",
            "Prediction --> Introvert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp4m7HXuhRVV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}