{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_HuggingFace(BenchmarkSeq2Seq).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPuCfxfBo28U5Pk+pIDk0an",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal-burman/PyTorch-Architectures/blob/master/misc/test_HuggingFace(BenchmarkSeq2Seq).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9_AkaEdVF7R"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0se2_pFWq-Y"
      },
      "source": [
        "! pip install transformers\n",
        "! pip install datasets\n",
        "! pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i543MNhnCnZj"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import Text2TextGenerationPipeline\n",
        "from transformers.optimization import Adafactor, AdafactorSchedule"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2DL74GjVIgV"
      },
      "source": [
        "dataset = load_dataset(\"squad\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2oEUUxMVda3"
      },
      "source": [
        "contexts_train, contexts_valid = [], []\n",
        "questions_train, questions_valid = [], []\n",
        "for idx, sample in enumerate(dataset[\"train\"]):\n",
        "  if idx == 5850:\n",
        "    break\n",
        "  contexts_train.append(sample[\"context\"])\n",
        "  questions_train.append(sample[\"question\"])\n",
        "assert len(contexts_train) == len(questions_train)\n",
        "assert len(contexts_train) == 5850\n",
        "\n",
        "for idx, sample in enumerate(dataset[\"validation\"]):\n",
        "  if idx == 650:\n",
        "    break\n",
        "  contexts_valid.append(sample[\"context\"])\n",
        "  questions_valid.append(sample[\"question\"])\n",
        "assert len(contexts_valid) == len(questions_valid)\n",
        "assert len(contexts_valid) == 650"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EGcth1mJ5LP"
      },
      "source": [
        "class CustomSeq2SeqLMDataset(Dataset):\n",
        "    def __init__(self, tokenizer, input_texts, target_texts, max_input_length=16, max_target_length=16):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_texts = input_texts\n",
        "        self.target_texts = target_texts\n",
        "        assert len(self.input_texts) == len(self.target_texts), 'Input and Target texts sizes do not match'\n",
        "        self.max_input_length = max_input_length\n",
        "        self.max_target_length = max_target_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_sentences = self.input_texts[idx]\n",
        "        target_sentences = self.target_texts[idx]\n",
        "        return {\n",
        "                'sents': input_sentences,\n",
        "                'labels': target_sentences,\n",
        "                }\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        sents = []\n",
        "        labels = []\n",
        "        for sample in batch:\n",
        "            sents.append(sample['sents'])\n",
        "            labels.append(sample['labels'])\n",
        "        tokens_input = self.tokenizer(sents,\n",
        "                max_length=self.max_input_length,\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "                )\n",
        "        tokens_target = self.tokenizer(labels,\n",
        "                max_length=self.max_target_length,\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "                )\n",
        "        if self.tokenizer.pad_token_id is not None:\n",
        "            labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "        return {\n",
        "                'input_ids': tokens_input['input_ids'],\n",
        "                'attention_mask': tokens_input['attention_mask'],\n",
        "                'labels': tokens_target['input_ids'],\n",
        "                }"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNWZKiY5K9uW"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_name = \"t5-base\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "model.to(device)\n",
        "\n",
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Trainable Parameters --> {params}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsEXzDMJMwlY"
      },
      "source": [
        "BS = 8\n",
        "INPUT_LENGTH = 512\n",
        "TARGET_LENGTH = 40"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBa20EtDLmX6",
        "outputId": "ceccfaf4-5e4b-4fbb-b087-49cfd5b1e6df"
      },
      "source": [
        "train_dataset = CustomSeq2SeqLMDataset(tokenizer=tokenizer,\n",
        "                                       input_texts=contexts_train,\n",
        "                                       target_texts=questions_train,\n",
        "                                       max_input_length=INPUT_LENGTH,\n",
        "                                       max_target_length=TARGET_LENGTH,\n",
        "                                       )\n",
        "\n",
        "valid_dataset = CustomSeq2SeqLMDataset(tokenizer=tokenizer,\n",
        "                                       input_texts=contexts_valid,\n",
        "                                       target_texts=questions_valid,\n",
        "                                       max_input_length=INPUT_LENGTH,\n",
        "                                       max_target_length=TARGET_LENGTH,\n",
        "                                       )\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BS, shuffle=False, collate_fn=valid_dataset.collate_fn)\n",
        "\n",
        "print('Length of Train Loader: ', len(train_loader))\n",
        "print('Length of Valid Loader: ', len(valid_loader))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of Train Loader:  732\n",
            "Length of Valid Loader:  82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6SV2mP5MQN1"
      },
      "source": [
        "# For AdaFactor\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',         \n",
        "    num_train_epochs=3,              \n",
        "    per_device_train_batch_size=BS,  \n",
        "    per_device_eval_batch_size=BS,\n",
        "    evaluation_strategy='epoch',\n",
        "    logging_strategy='epoch',\n",
        "    save_strategy='no',\n",
        "    fp16=False,\n",
        "    gradient_accumulation_steps=(128 // BS),\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO5vWHjANfg1"
      },
      "source": [
        "optimizer = Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n",
        "lr_scheduler = AdafactorSchedule(optimizer)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0b9iOfsNu1x"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=train_dataset.collate_fn,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    optimizers=(optimizer, lr_scheduler),\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_awDVnddOBPU"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtBBJMgiOEbO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}