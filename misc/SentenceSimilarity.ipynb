{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentenceSimilarity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxgjecj4YiLMGSdqeRH9vZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "64d1e75e4a8e4f2e836745cdb74c33ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_697cbf2411e84bd9b9cc483ebeb4f1b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ad87fe9f5b474de79f30607e4967992f",
              "IPY_MODEL_643d0f2be38d44259e73e0f3702a4640",
              "IPY_MODEL_c060e2b6583e4f2d94bb65e5b6fdfb6c"
            ]
          }
        },
        "697cbf2411e84bd9b9cc483ebeb4f1b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad87fe9f5b474de79f30607e4967992f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f9c1802466cf444198d4191a527cd060",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  6%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_490b40db69154354a21658af4e485d6b"
          }
        },
        "643d0f2be38d44259e73e0f3702a4640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_451f8df4ec92479ca8e63f62268cb491",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 15700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 942,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22483f88a9f24c02b7d460590192b462"
          }
        },
        "c060e2b6583e4f2d94bb65e5b6fdfb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76d96be047bd4bbbb1269eb56af8eb12",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 942/15700 [23:43&lt;4:33:54,  1.11s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65fbdbdaaa6847c38a62ba5b8e328728"
          }
        },
        "f9c1802466cf444198d4191a527cd060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "490b40db69154354a21658af4e485d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "451f8df4ec92479ca8e63f62268cb491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22483f88a9f24c02b7d460590192b462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76d96be047bd4bbbb1269eb56af8eb12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65fbdbdaaa6847c38a62ba5b8e328728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal-burman/PyTorch-Architectures/blob/master/misc/SentenceSimilarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgCrLMn_Rjcm"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obXzgtA5E_bu"
      },
      "source": [
        "! pip install transformers\n",
        "! pip install datasets\n",
        "! pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtI73nn1Fdww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "845b7dd2-d11d-4346-b0e4-b5097c81f80b"
      },
      "source": [
        "! git clone https://github.com/vishal-burman/PyTorch-Architectures.git\n",
        "%cd PyTorch-Architectures/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'PyTorch-Architectures' already exists and is not an empty directory.\n",
            "/content/PyTorch-Architectures\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGkAof1sF4bd"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from toolkit.utils import get_optimal_batchsize, get_linear_schedule_with_warmup\n",
        "from toolkit.utils import dict_to_device, EarlyStopping"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx4TjrOBGPJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ef4076-ce96-4814-c250-c7b62e8ece00"
      },
      "source": [
        "dataset = load_dataset(\"quora\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset quora (/root/.cache/huggingface/datasets/quora/default/0.0.0/36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6Jo-84oGUA-",
        "outputId": "06a11f23-7f93-44a1-93cb-256d09275c93"
      },
      "source": [
        "train_p = []\n",
        "train_n = []\n",
        "test_list = []\n",
        "count_p, count_n = 0, 0\n",
        "for idx, sample in enumerate(dataset[\"train\"]):\n",
        "  text_1, text_2 = sample[\"questions\"][\"text\"][0], sample[\"questions\"][\"text\"][1]\n",
        "  if len(train_p) < 20000 and sample[\"is_duplicate\"]:\n",
        "    train_p.append((text_1, text_2, 1))\n",
        "  elif len(train_n) < 20000 and not sample[\"is_duplicate\"]:\n",
        "    train_n.append((text_1, text_2, 0))\n",
        "  elif len(test_list) < 10000:\n",
        "    is_duplicate = 1 if sample[\"is_duplicate\"] else 0\n",
        "    test_list.append((text_1, text_2, is_duplicate))\n",
        "train_list = []\n",
        "train_list.extend(train_p)\n",
        "train_list.extend(train_n)\n",
        "random.shuffle(train_list)\n",
        "print(f\"No. of Train Samples: {len(train_list)} || No. of Test Samples: {len(test_list)}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of Train Samples: 40000 || No. of Test Samples: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urtItUP2p-YU"
      },
      "source": [
        "path_str = \"distilbert-base-uncased\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF0tPyU_tnVL"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, path_str: str, list_samples: list, max_input_length: int = 16):\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(path_str)\n",
        "    self.list_samples = list_samples\n",
        "    self.max_input_length = max_input_length\n",
        "  \n",
        "  def __len__(self,):\n",
        "    return len(self.list_samples)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    sample = self.list_samples[idx]\n",
        "    return {\n",
        "        'text_1': sample[0],\n",
        "        'text_2': sample[1],\n",
        "        'is_duplicate': sample[2],\n",
        "    }\n",
        "  \n",
        "  def collate_fn(self, batch):\n",
        "    text_1 = []\n",
        "    text_2 = []\n",
        "    labels = []\n",
        "    for sample in batch:\n",
        "      text_1.append(sample[\"text_1\"])\n",
        "      text_2.append(sample[\"text_2\"])\n",
        "      labels.append(sample[\"is_duplicate\"])\n",
        "    tokens_1 = self.tokenizer(text_1,\n",
        "                              max_length=self.max_input_length,\n",
        "                              padding=True,\n",
        "                              truncation=True,\n",
        "                              return_tensors=\"pt\",\n",
        "                              )\n",
        "    tokens_2 = self.tokenizer(text_2,\n",
        "                              max_length=self.max_input_length,\n",
        "                              padding=True,\n",
        "                              truncation=True,\n",
        "                              return_tensors=\"pt\",\n",
        "                              )\n",
        "    ids_1, att_1 = tokens_1[\"input_ids\"], tokens_1[\"attention_mask\"]\n",
        "    ids_2, att_2 = tokens_2[\"input_ids\"], tokens_2[\"attention_mask\"]\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "    return {\n",
        "        \"input_ids_1\": ids_1,\n",
        "        \"attention_mask_1\": att_1,\n",
        "        \"input_ids_2\": ids_2,\n",
        "        \"attention_mask_2\": att_2,\n",
        "        \"labels\": labels,\n",
        "    }"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcVia23ZWFSt"
      },
      "source": [
        "class Residual(nn.Module):\n",
        "  def __init__(self, fn):\n",
        "      super().__init__()\n",
        "      self.fn = fn\n",
        "  def forward(self, x, **kwargs):\n",
        "      return self.fn(x, **kwargs) + x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Neq816gvWAE6"
      },
      "source": [
        "class PreNorm(nn.Module):\n",
        "  def __init__(self, dim, fn):\n",
        "      super().__init__()\n",
        "      self.norm = nn.LayerNorm(dim)\n",
        "      self.fn = fn\n",
        "  def forward(self, x, **kwargs):\n",
        "      return self.fn(self.norm(x), **kwargs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDdpVXNdVqAM"
      },
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "      super().__init__()\n",
        "      self.net = nn.Sequential(\n",
        "              nn.Linear(dim, hidden_dim),\n",
        "              nn.GELU(),\n",
        "              nn.Dropout(dropout),\n",
        "              nn.Linear(hidden_dim, dim),\n",
        "              nn.Dropout(dropout),\n",
        "              )\n",
        "  def forward(self, x):\n",
        "      return self.net(x)  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb0vcbhXGtz9"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, in_size: int = 768, hidden_size: int = 512):\n",
        "    super().__init__()\n",
        "    self.W = nn.Linear(in_size, hidden_size)\n",
        "    self.V = nn.Linear(hidden_size, 1)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = torch.tanh(self.W(x))\n",
        "    score = self.V(x)\n",
        "    attention_weights = score.softmax(dim=1)\n",
        "    context_vector = x * attention_weights\n",
        "    context_vector = torch.sum(context_vector, dim=1)\n",
        "    output = self.dropout(context_vector)\n",
        "    return output"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwKwlQjnJoNq"
      },
      "source": [
        "class SentenceSimilarity(nn.Module):\n",
        "  def __init__(self, path_str: str, in_size: int = 768, hidden_size: int = 768):\n",
        "    super().__init__()\n",
        "    self.encoder = AutoModel.from_pretrained(path_str)\n",
        "    self.attention = Attention(in_size, hidden_size)\n",
        "    cat_dim = hidden_size * 2\n",
        "    self.intermediate_layer = Residual(PreNorm(cat_dim, FeedForward(cat_dim, cat_dim * 4, dropout=0.1)))\n",
        "    self.output_layer = nn.Linear(hidden_size * 2, 2)\n",
        "  \n",
        "  def forward(self,\n",
        "              input_ids_1,\n",
        "              attention_mask_1,\n",
        "              input_ids_2,\n",
        "              attention_mask_2,\n",
        "              labels=None,\n",
        "              ):\n",
        "    \n",
        "    outputs_1 = self.encoder(input_ids=input_ids_1,\n",
        "                               attention_mask=attention_mask_1)\n",
        "    outputs_2 = self.encoder(input_ids=input_ids_2,\n",
        "                               attention_mask=attention_mask_2)\n",
        "    \n",
        "    enc_weights_1 = self.attention(outputs_1.last_hidden_state)\n",
        "    enc_weights_2 = self.attention(outputs_2.last_hidden_state)\n",
        "\n",
        "    output = torch.cat([enc_weights_1, enc_weights_2], dim=1)\n",
        "    output = self.intermediate_layer(output)\n",
        "\n",
        "    logits = self.output_layer(output)\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss_fct = nn.CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(logits.size(0), -1), labels.view(-1))\n",
        "    return (loss, logits)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyViEY4cQBJp"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SentenceSimilarity(path_str=path_str)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPzpP8qQQY-A",
        "outputId": "bb56beda-bae0-4caf-bad9-8d5851c1fde7"
      },
      "source": [
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Trainable Parameters: {params}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable Parameters: 85842435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759yadjXQncK"
      },
      "source": [
        "# Create Datasets\n",
        "dataset_train = CustomDataset(path_str=path_str,\n",
        "                              list_samples=train_list,\n",
        "                              max_input_length=32,\n",
        "                              )\n",
        "dataset_valid = CustomDataset(path_str=path_str,\n",
        "                              list_samples=test_list,\n",
        "                              max_input_length=32,\n",
        "                              )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyl0neZFRENU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc99cc2-2d19-4f26-81ef-e3c38fdd83f4"
      },
      "source": [
        "# get_optimal_batchsize(dataset_train, model, fp16=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch-Size: 256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMI0GqqbRdL8"
      },
      "source": [
        "# Hyperparameter section\n",
        "BS = 256\n",
        "EPOCHS = 100\n",
        "LR = 3e-5"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsZbNAUbTFf3",
        "outputId": "d6a74fd3-a7c6-4520-ab7e-5a6844dabf8d"
      },
      "source": [
        "train_loader = DataLoader(dataset=dataset_train,\n",
        "                          batch_size=BS,\n",
        "                          shuffle=True,\n",
        "                          collate_fn=dataset_train.collate_fn,\n",
        "                          )\n",
        "valid_loader = DataLoader(dataset=dataset_valid,\n",
        "                          batch_size=BS,\n",
        "                          shuffle=True,\n",
        "                          collate_fn=dataset_valid.collate_fn,\n",
        "                          )\n",
        "print(f\"Length of Train Loader: {len(train_loader)} || Length of Valid Loader: {len(valid_loader)}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Train Loader: 157 || Length of Valid Loader: 40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SidUxZwvT-tU"
      },
      "source": [
        "early_stop = EarlyStopping(metric=\"val_accuracy\", patience=5, verbose=True)\n",
        "num_training_steps = len(train_loader) * EPOCHS\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer=optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=num_training_steps,\n",
        "                                            )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "64d1e75e4a8e4f2e836745cdb74c33ae",
            "697cbf2411e84bd9b9cc483ebeb4f1b9",
            "ad87fe9f5b474de79f30607e4967992f",
            "643d0f2be38d44259e73e0f3702a4640",
            "c060e2b6583e4f2d94bb65e5b6fdfb6c",
            "f9c1802466cf444198d4191a527cd060",
            "490b40db69154354a21658af4e485d6b",
            "451f8df4ec92479ca8e63f62268cb491",
            "22483f88a9f24c02b7d460590192b462",
            "76d96be047bd4bbbb1269eb56af8eb12",
            "65fbdbdaaa6847c38a62ba5b8e328728"
          ]
        },
        "id": "I8sY9vFyTlYW",
        "outputId": "aad3c71c-8d42-4171-9925-3ac143c2a15e"
      },
      "source": [
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "def get_accuracy(model, data_loader, device):\n",
        "  if model.training:\n",
        "    print(\"Model is in train mode...switching to eval mode!\")\n",
        "    model.eval()\n",
        "  \n",
        "  correct, total = 0, 0\n",
        "  with torch.set_grad_enabled(False):\n",
        "    for sample in data_loader:\n",
        "      sample = dict_to_device(sample, device=device)\n",
        "      labels = sample[\"labels\"].view(-1)\n",
        "      \n",
        "      \n",
        "      outputs = model(**sample)\n",
        "\n",
        "      _, logits = outputs\n",
        "      \n",
        "      probs = torch.softmax(logits, dim=-1)\n",
        "      _, preds = torch.max(probs, dim=-1)\n",
        "      correct += (preds == labels).sum()\n",
        "      total += labels.size(0)\n",
        "  return (correct / total * 100).item()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  model.train()\n",
        "  for sample in train_loader:\n",
        "    outputs = model(**dict_to_device(sample, device=device))\n",
        "\n",
        "    loss, _ = outputs\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "    progress_bar.update(1)\n",
        "  model.eval()\n",
        "  with torch.set_grad_enabled(False):\n",
        "    valid_acc = get_accuracy(model, valid_loader, device)\n",
        "    early_stop(valid_acc, model)\n",
        "    if early_stop.early_stop:\n",
        "      print(\"Early Stopping!\")\n",
        "      break"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64d1e75e4a8e4f2e836745cdb74c33ae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/15700 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy increased from -inf% to 75.48%\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early Stopping!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-E4ThxcWsaS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}