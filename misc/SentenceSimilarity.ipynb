{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentenceSimilarity(DistilRoBERTa_DistilRoBERTa).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSOsmEecuIqtckLVxIspFH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4e27ff9605f6453e8e4ad49aa8242982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_26e24ea02dd34249a99232e389b5ce62",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7f67d7cf20e34ab48dacbbfe08af4ec5",
              "IPY_MODEL_5579250965c54180aa5b103e6e26e592",
              "IPY_MODEL_e23454daea2a4c4486f056c5165e002a"
            ]
          }
        },
        "26e24ea02dd34249a99232e389b5ce62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f67d7cf20e34ab48dacbbfe08af4ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a722133ebfd0497bb4310872ec1e4fab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0365fe98cbee4ad3bb2c476a1c5b5c46"
          }
        },
        "5579250965c54180aa5b103e6e26e592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9620b21db67b4352960a9b54e76fdc9b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 15700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1727,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0899330411fd46a4839b2f86b9bfd802"
          }
        },
        "e23454daea2a4c4486f056c5165e002a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0219231a83b548e9901cf611f48cd1ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1727/15700 [45:58&lt;4:33:34,  1.17s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1e1abb32a4945f7abe3a0757abc153c"
          }
        },
        "a722133ebfd0497bb4310872ec1e4fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0365fe98cbee4ad3bb2c476a1c5b5c46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9620b21db67b4352960a9b54e76fdc9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0899330411fd46a4839b2f86b9bfd802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0219231a83b548e9901cf611f48cd1ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1e1abb32a4945f7abe3a0757abc153c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal-burman/PyTorch-Architectures/blob/master/misc/SentenceSimilarity(DistilRoBERTa_DistilRoBERTa).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgCrLMn_Rjcm"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obXzgtA5E_bu"
      },
      "source": [
        "! pip install transformers\n",
        "! pip install datasets\n",
        "! pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtI73nn1Fdww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "426c250f-7645-4e6c-bac2-32d42c902f8e"
      },
      "source": [
        "! git clone https://github.com/vishal-burman/PyTorch-Architectures.git\n",
        "%cd PyTorch-Architectures/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'PyTorch-Architectures' already exists and is not an empty directory.\n",
            "/content/PyTorch-Architectures\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGkAof1sF4bd"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from toolkit.utils import get_optimal_batchsize, get_linear_schedule_with_warmup\n",
        "from toolkit.utils import dict_to_device, EarlyStopping"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx4TjrOBGPJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92965945-5221-4691-d18a-cb0eb7f8ca2b"
      },
      "source": [
        "dataset = load_dataset(\"quora\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset quora (/root/.cache/huggingface/datasets/quora/default/0.0.0/36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6Jo-84oGUA-",
        "outputId": "4194a805-f6d7-4b44-c2fa-7251c9fa6347"
      },
      "source": [
        "train_p = []\n",
        "train_n = []\n",
        "test_list = []\n",
        "count_p, count_n = 0, 0\n",
        "for idx, sample in enumerate(dataset[\"train\"]):\n",
        "  text_1, text_2 = sample[\"questions\"][\"text\"][0], sample[\"questions\"][\"text\"][1]\n",
        "  if len(train_p) < 20000 and sample[\"is_duplicate\"]:\n",
        "    train_p.append((text_1, text_2, 1))\n",
        "  elif len(train_n) < 20000 and not sample[\"is_duplicate\"]:\n",
        "    train_n.append((text_1, text_2, 0))\n",
        "  elif len(test_list) < 10000:\n",
        "    is_duplicate = 1 if sample[\"is_duplicate\"] else 0\n",
        "    test_list.append((text_1, text_2, is_duplicate))\n",
        "train_list = []\n",
        "train_list.extend(train_p)\n",
        "train_list.extend(train_n)\n",
        "random.shuffle(train_list)\n",
        "print(f\"No. of Train Samples: {len(train_list)} || No. of Test Samples: {len(test_list)}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of Train Samples: 40000 || No. of Test Samples: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urtItUP2p-YU"
      },
      "source": [
        "# path_str = \"distilroberta-base\"\n",
        "path_str = \"distilbert-base-uncased\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF0tPyU_tnVL"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, path_str: str, list_samples: list, max_input_length: int = 16):\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(path_str)\n",
        "    self.list_samples = list_samples\n",
        "    self.max_input_length = max_input_length\n",
        "  \n",
        "  def __len__(self,):\n",
        "    return len(self.list_samples)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    sample = self.list_samples[idx]\n",
        "    return {\n",
        "        'text_1': sample[0],\n",
        "        'text_2': sample[1],\n",
        "        'is_duplicate': sample[2],\n",
        "    }\n",
        "  \n",
        "  def collate_fn(self, batch):\n",
        "    text_1 = []\n",
        "    text_2 = []\n",
        "    labels = []\n",
        "    for sample in batch:\n",
        "      text_1.append(sample[\"text_1\"])\n",
        "      text_2.append(sample[\"text_2\"])\n",
        "      labels.append(sample[\"is_duplicate\"])\n",
        "    tokens_1 = self.tokenizer(text_1,\n",
        "                              max_length=self.max_input_length,\n",
        "                              padding=True,\n",
        "                              truncation=True,\n",
        "                              return_tensors=\"pt\",\n",
        "                              )\n",
        "    tokens_2 = self.tokenizer(text_2,\n",
        "                              max_length=self.max_input_length,\n",
        "                              padding=True,\n",
        "                              truncation=True,\n",
        "                              return_tensors=\"pt\",\n",
        "                              )\n",
        "    ids_1, att_1 = tokens_1[\"input_ids\"], tokens_1[\"attention_mask\"]\n",
        "    ids_2, att_2 = tokens_2[\"input_ids\"], tokens_2[\"attention_mask\"]\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "    return {\n",
        "        \"input_ids_1\": ids_1,\n",
        "        \"attention_mask_1\": att_1,\n",
        "        \"input_ids_2\": ids_2,\n",
        "        \"attention_mask_2\": att_2,\n",
        "        \"labels\": labels,\n",
        "    }"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb0vcbhXGtz9"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, in_size: int = 768, hidden_size: int = 512):\n",
        "    super().__init__()\n",
        "    self.W = nn.Linear(in_size, hidden_size)\n",
        "    self.V = nn.Linear(hidden_size, 1)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = torch.tanh(self.W(x))\n",
        "    score = self.V(x)\n",
        "    attention_weights = score.softmax(dim=1)\n",
        "    context_vector = x * attention_weights\n",
        "    context_vector = torch.sum(context_vector, dim=1)\n",
        "    output = self.dropout(context_vector)\n",
        "    return output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwKwlQjnJoNq"
      },
      "source": [
        "class SentenceSimilarity(nn.Module):\n",
        "  def __init__(self, path_str: str, in_size: int = 768, hidden_size: int = 768):\n",
        "    super().__init__()\n",
        "    self.encoder = AutoModel.from_pretrained(path_str)\n",
        "    self.attention = Attention(in_size, hidden_size)\n",
        "    self.ff = nn.Linear(hidden_size * 2, 2)\n",
        "  \n",
        "  def forward(self,\n",
        "              input_ids_1,\n",
        "              attention_mask_1,\n",
        "              input_ids_2,\n",
        "              attention_mask_2,\n",
        "              labels=None,\n",
        "              ):\n",
        "    \n",
        "    outputs_1 = self.encoder(input_ids=input_ids_1,\n",
        "                               attention_mask=attention_mask_1)\n",
        "    outputs_2 = self.encoder(input_ids=input_ids_2,\n",
        "                               attention_mask=attention_mask_2)\n",
        "    \n",
        "    enc_weights_1 = self.attention(outputs_1.last_hidden_state)\n",
        "    enc_weights_2 = self.attention(outputs_2.last_hidden_state)\n",
        "\n",
        "    output = torch.cat([enc_weights_1, enc_weights_2], dim=1)\n",
        "\n",
        "    logits = self.ff(output)\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss_fct = nn.CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(logits.size(0), -1), labels.view(-1))\n",
        "    return (loss, logits)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyViEY4cQBJp"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SentenceSimilarity(path_str=path_str)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPzpP8qQQY-A",
        "outputId": "44796e45-e1d7-4bfd-ed15-7fa235d6df29"
      },
      "source": [
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Trainable Parameters: {params}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable Parameters: 66957315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759yadjXQncK"
      },
      "source": [
        "# Create Datasets\n",
        "dataset_train = CustomDataset(path_str=path_str,\n",
        "                              list_samples=train_list,\n",
        "                              max_input_length=32,\n",
        "                              )\n",
        "dataset_valid = CustomDataset(path_str=path_str,\n",
        "                              list_samples=test_list,\n",
        "                              max_input_length=32,\n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyl0neZFRENU"
      },
      "source": [
        "# get_optimal_batchsize(dataset_train, model, fp16=False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMI0GqqbRdL8"
      },
      "source": [
        "# Hyperparameter section\n",
        "BS = 256\n",
        "EPOCHS = 100\n",
        "LR = 3e-5"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsZbNAUbTFf3",
        "outputId": "665b8d65-ba8c-4d27-f290-f75958c672a6"
      },
      "source": [
        "train_loader = DataLoader(dataset=dataset_train,\n",
        "                          batch_size=BS,\n",
        "                          shuffle=True,\n",
        "                          collate_fn=dataset_train.collate_fn,\n",
        "                          )\n",
        "valid_loader = DataLoader(dataset=dataset_valid,\n",
        "                          batch_size=BS,\n",
        "                          shuffle=True,\n",
        "                          collate_fn=dataset_valid.collate_fn,\n",
        "                          )\n",
        "print(f\"Length of Train Loader: {len(train_loader)} || Length of Valid Loader: {len(valid_loader)}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Train Loader: 157 || Length of Valid Loader: 40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SidUxZwvT-tU"
      },
      "source": [
        "early_stop = EarlyStopping(metric=\"val_accuracy\", patience=5, verbose=True)\n",
        "num_training_steps = len(train_loader) * EPOCHS\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer=optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=num_training_steps,\n",
        "                                            )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "4e27ff9605f6453e8e4ad49aa8242982",
            "26e24ea02dd34249a99232e389b5ce62",
            "7f67d7cf20e34ab48dacbbfe08af4ec5",
            "5579250965c54180aa5b103e6e26e592",
            "e23454daea2a4c4486f056c5165e002a",
            "a722133ebfd0497bb4310872ec1e4fab",
            "0365fe98cbee4ad3bb2c476a1c5b5c46",
            "9620b21db67b4352960a9b54e76fdc9b",
            "0899330411fd46a4839b2f86b9bfd802",
            "0219231a83b548e9901cf611f48cd1ee",
            "f1e1abb32a4945f7abe3a0757abc153c"
          ]
        },
        "id": "I8sY9vFyTlYW",
        "outputId": "cc06e8d9-4cd1-4136-f2a9-bcb0d99669fb"
      },
      "source": [
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "def get_accuracy(model, data_loader, device):\n",
        "  if model.training:\n",
        "    print(\"Model is in train mode...switching to eval mode!\")\n",
        "    model.eval()\n",
        "  \n",
        "  correct, total = 0, 0\n",
        "  with torch.set_grad_enabled(False):\n",
        "    for sample in data_loader:\n",
        "      sample = dict_to_device(sample, device=device)\n",
        "      labels = sample[\"labels\"].view(-1)\n",
        "      \n",
        "      \n",
        "      outputs = model(**sample)\n",
        "\n",
        "      _, logits = outputs\n",
        "      \n",
        "      probs = torch.softmax(logits, dim=-1)\n",
        "      _, preds = torch.max(probs, dim=-1)\n",
        "      correct += (preds == labels).sum()\n",
        "      total += labels.size(0)\n",
        "  return (correct / total * 100).item()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  model.train()\n",
        "  for sample in train_loader:\n",
        "    outputs = model(**dict_to_device(sample, device=device))\n",
        "\n",
        "    loss, _ = outputs\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "    progress_bar.update(1)\n",
        "  model.eval()\n",
        "  with torch.set_grad_enabled(False):\n",
        "    valid_acc = get_accuracy(model, valid_loader, device)\n",
        "    early_stop(valid_acc, model)\n",
        "    if early_stop.early_stop:\n",
        "      print(\"Early Stopping!\")\n",
        "      break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e27ff9605f6453e8e4ad49aa8242982",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/15700 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy increased from -inf% to 61.01%\n",
            "Validation accuracy increased from 61.01% to 62.78%\n",
            "Validation accuracy increased from 62.78% to 67.57%\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Validation accuracy increased from 67.57% to 74.11%\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early Stopping!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-E4ThxcWsaS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}