{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_sample_TextBiLSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJMGGn3N4tA5ooM12xQU92",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal-burman/PyTorch-Architectures/blob/master/modeling_TextBiLSTM/test_sample_TextBiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D-pfXWOYrnk"
      },
      "source": [
        "! pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krHP9uwOYYzW"
      },
      "source": [
        "! git clone https://github.com/vishal-burman/PyTorch-Architectures.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQZjfcIXYkyY",
        "outputId": "3bbf1038-36d1-4ca7-f036-956d976aee2a"
      },
      "source": [
        "%cd PyTorch-Architectures/modeling_TextBiLSTM/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PyTorch-Architectures/modeling_TextBiLSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEt3ZEC-YnkZ",
        "outputId": "4d6d79a4-8d23-4429-fc8f-ff9cc1b35278"
      },
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from model import TextBiLSTM\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset('quora')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset quora (/root/.cache/huggingface/datasets/quora/default/0.0.0/2be517cf0ac6de94b77a103a36b141347a13f40637fbebaccb56ddbe397876be)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNH29xbkYpS6"
      },
      "source": [
        "sentences = []\n",
        "for sample in dataset['train']:\n",
        "  if len(sentences) == 10000:\n",
        "    break\n",
        "  sent = sample['questions']['text'][0]\n",
        "  if len(sent.split()) >= 4:\n",
        "    sentences.append(sent)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-IM8H28Y2ml",
        "outputId": "771c7fb6-9d89-432a-8d44-f20a35161f64"
      },
      "source": [
        "word_list = ' '.join(sentences).split()\n",
        "word_list = list(set(word_list))\n",
        "\n",
        "word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "number_dict = {i: w for i, w in enumerate(word_list)}\n",
        "n_class = len(word_dict)\n",
        "print('Vocabulary Size: ', n_class)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size:  18198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eslJpss_Y3Ew"
      },
      "source": [
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, list_sentences, max_inp_length=4):\n",
        "    self.list_sentences = list_sentences\n",
        "    self.max_inp_length = max_inp_length\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.list_sentences)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "    sentences = self.list_sentences[idx]\n",
        "    tokens = self.tokenize_into_tensors(sentences)\n",
        "    return {\n",
        "        'input_batch': tokens['inp_batch'],\n",
        "        'target_batch': tokens['tgt_batch'],\n",
        "    }\n",
        "  \n",
        "  def tokenize_into_tensors(self, sentence):\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "    word = sentence.split()\n",
        "    word = word[:self.max_inp_length]\n",
        "    input_tokens = [word_dict[n] for n in word[:-1]]\n",
        "    target_tokens = word_dict[word[-1]]\n",
        "    input_batch.append(input_tokens)\n",
        "    target_batch.append(target_tokens)\n",
        "    return {\n",
        "        'inp_batch': torch.tensor(input_batch),\n",
        "        'tgt_batch': torch.tensor(target_batch),\n",
        "    }"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7We0KqtHY5c2",
        "outputId": "f0a11a6a-dcef-41a2-9747-1908bfb4dadb"
      },
      "source": [
        "lim = 90 * len(sentences) // 100\n",
        "train_sentences = sentences[:lim]\n",
        "valid_sentences = sentences[lim:]\n",
        "print('Train Samples: ', len(train_sentences))\n",
        "print('Valid Samples: ', len(valid_sentences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Samples:  9000\n",
            "Valid Samples:  1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxqHBy1NY7Hs"
      },
      "source": [
        "train_dataset = CustomDataset(train_sentences, max_inp_length=4)\n",
        "valid_dataset = CustomDataset(valid_sentences, max_inp_length=4)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scSRuWAqY_TH"
      },
      "source": [
        "# Hyperparameters\n",
        "VOCAB_SIZE = n_class\n",
        "EMBEDDING_SIZE = 32\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 4"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN5-mvHjZFOp",
        "outputId": "758913f4-2f31-4912-9f1c-f65a2a30139d"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = TextBiLSTM(vocab_size=VOCAB_SIZE, embedding_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE)\n",
        "model.to(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBiLSTM(\n",
              "  (embedding): Embedding(18198, 32)\n",
              "  (lstm): LSTM(32, 128, bidirectional=True)\n",
              "  (W): Linear(in_features=256, out_features=18198, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjRZc0ByZJir",
        "outputId": "c814400c-fd5f-4117-c759-2ac45abb1aa8"
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Sanity check DataLoader\n",
        "for sample in train_loader:\n",
        "  assert sample['input_batch'].squeeze(1).dim() == 2\n",
        "  assert sample['target_batch'].dim() == 2\n",
        "  break\n",
        "\n",
        "print('Length of Train Loader: ', len(train_loader))\n",
        "print('Length of Valid Loader: ', len(valid_loader))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Train Loader:  282\n",
            "Length of Valid Loader:  32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FBMn7YxZNxI"
      },
      "source": [
        "# Sanity check model outputs\n",
        "model.eval()\n",
        "with torch.set_grad_enabled(False):\n",
        "  outputs = model(sample['input_batch'].squeeze(1))\n",
        "  assert outputs.size(1) == n_class"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABE0Ey9FZQnw"
      },
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUcRVZcWZSCb",
        "outputId": "f8736e42-bf06-43dd-b4ed-2aa266462f2c"
      },
      "source": [
        "def compute_loss(model, data_loader, device):\n",
        "  list_loss = []\n",
        "  with torch.set_grad_enabled(False):\n",
        "    for sample in data_loader:\n",
        "      features = sample['input_batch'].squeeze(1)\n",
        "      targets = sample['target_batch'].squeeze(1)\n",
        "\n",
        "      logits = model(features)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "      list_loss.append(loss.item())\n",
        "  return torch.tensor(list_loss).mean()\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(EPOCHS):\n",
        "  model.train()\n",
        "  for idx, sample in enumerate(train_loader):\n",
        "    features = sample['input_batch'].squeeze(1)\n",
        "    targets = sample['target_batch'].squeeze(1)\n",
        "\n",
        "    logits = model(features)\n",
        "    loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # LOGGING\n",
        "    if idx % 50 == 0:\n",
        "      print('Batch: %04d/%04d || Epoch: %04d/%04d || Loss: %.2f' % (idx, len(train_loader), epoch+1, EPOCHS, loss.item()))\n",
        "  \n",
        "  model.eval()\n",
        "  with torch.set_grad_enabled(False):\n",
        "    train_loss = compute_loss(model, train_loader, device)\n",
        "    valid_loss = compute_loss(model, valid_loader, device)\n",
        "\n",
        "    print('Train Loss: %.2f' % (train_loss.item()))\n",
        "    print('Valid Loss: %.2f' % (valid_loss.item()))\n",
        "  epoch_elapsed_time = (time.time() - start_time) / 60\n",
        "  print('Epoch Elapsed Time: %.2f min' % (epoch_elapsed_time))\n",
        "total_training_time = (time.time() - start_time) / 60\n",
        "print('Total Training Time: %.2f min' % (total_training_time))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch: 0000/0282 || Epoch: 0001/0004 || Loss: 9.80\n",
            "Batch: 0050/0282 || Epoch: 0001/0004 || Loss: 8.33\n",
            "Batch: 0100/0282 || Epoch: 0001/0004 || Loss: 7.10\n",
            "Batch: 0150/0282 || Epoch: 0001/0004 || Loss: 7.57\n",
            "Batch: 0200/0282 || Epoch: 0001/0004 || Loss: 7.03\n",
            "Batch: 0250/0282 || Epoch: 0001/0004 || Loss: 6.68\n",
            "Train Loss: 6.11\n",
            "Valid Loss: 6.74\n",
            "Epoch Elapsed Time: 0.41 min\n",
            "Batch: 0000/0282 || Epoch: 0002/0004 || Loss: 5.80\n",
            "Batch: 0050/0282 || Epoch: 0002/0004 || Loss: 5.74\n",
            "Batch: 0100/0282 || Epoch: 0002/0004 || Loss: 6.16\n",
            "Batch: 0150/0282 || Epoch: 0002/0004 || Loss: 5.32\n",
            "Batch: 0200/0282 || Epoch: 0002/0004 || Loss: 6.35\n",
            "Batch: 0250/0282 || Epoch: 0002/0004 || Loss: 4.87\n",
            "Train Loss: 5.16\n",
            "Valid Loss: 6.64\n",
            "Epoch Elapsed Time: 0.84 min\n",
            "Batch: 0000/0282 || Epoch: 0003/0004 || Loss: 5.05\n",
            "Batch: 0050/0282 || Epoch: 0003/0004 || Loss: 4.61\n",
            "Batch: 0100/0282 || Epoch: 0003/0004 || Loss: 4.97\n",
            "Batch: 0150/0282 || Epoch: 0003/0004 || Loss: 4.65\n",
            "Batch: 0200/0282 || Epoch: 0003/0004 || Loss: 5.49\n",
            "Batch: 0250/0282 || Epoch: 0003/0004 || Loss: 4.85\n",
            "Train Loss: 4.48\n",
            "Valid Loss: 6.64\n",
            "Epoch Elapsed Time: 1.24 min\n",
            "Batch: 0000/0282 || Epoch: 0004/0004 || Loss: 4.90\n",
            "Batch: 0050/0282 || Epoch: 0004/0004 || Loss: 4.50\n",
            "Batch: 0100/0282 || Epoch: 0004/0004 || Loss: 4.39\n",
            "Batch: 0150/0282 || Epoch: 0004/0004 || Loss: 4.29\n",
            "Batch: 0200/0282 || Epoch: 0004/0004 || Loss: 4.53\n",
            "Batch: 0250/0282 || Epoch: 0004/0004 || Loss: 4.10\n",
            "Train Loss: 3.83\n",
            "Valid Loss: 6.74\n",
            "Epoch Elapsed Time: 1.65 min\n",
            "Total Training Time: 1.65 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t6S62sqZVFy",
        "outputId": "994c2409-91e3-448e-dc21-1f75181d704f"
      },
      "source": [
        "model.eval()\n",
        "with torch.set_grad_enabled(False):\n",
        "  text = \"What is the\".split()\n",
        "  input_tokens = [word_dict[n] for n in text]\n",
        "  input_tokens = torch.tensor(input_tokens).unsqueeze(0)\n",
        "  logits = model(input_tokens)\n",
        "  probas = F.softmax(logits, dim=1)\n",
        "  _, predicted_word_idx = torch.max(probas, 1)\n",
        "  print('Your input --> ', ' '.join(text))\n",
        "  print('Predicted next token --> ', number_dict[predicted_word_idx.item()])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your input -->  What is the\n",
            "Predicted next token -->  best\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqKHUeh0axOa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}