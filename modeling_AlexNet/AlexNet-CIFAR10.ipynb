{"cells":[{"metadata":{"_uuid":"1741515e-8d57-4915-b6ec-096f128eb6bb","_cell_guid":"228bae07-faa0-4995-aafe-c7f05abc14e7","trusted":true},"cell_type":"code","source":"import os\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.dataset import Subset\n\nfrom torchvision import datasets\nfrom torchvision import transforms\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"e3b8ed0f-7eff-48a4-a378-e298ce5def5d","_cell_guid":"49b2be7c-67b4-48f5-8f26-ba3b26c2e2e7","trusted":true},"cell_type":"code","source":"# SETTINGS\n\n# Model Settings\nrandom_seed=1\nlearning_rate=0.0001\nbatch_size=256\nnum_epochs=20\n\n# Architecture\nnum_classes=10\n\n# Other\ndevice=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"be8da634-d0a2-4eac-aacf-e6fe200e5137","_cell_guid":"5f46e40d-8c3b-4a3d-9ba2-eba5af63a4b6","trusted":true},"cell_type":"code","source":"# Dataset\ntrain_indices=torch.arange(0, 48000)\nvalid_indices=torch.arange(48000, 50000)\n\ntrain_transform=transforms.Compose([transforms.Resize((70, 70)),\n                                    transforms.RandomCrop((64, 64)),\n                                    transforms.ToTensor()])\n\ntest_transform=transforms.Compose([transforms.Resize((70, 70)),\n                                   transforms.CenterCrop((64, 64)),\n                                   transforms.ToTensor()])\n\ntrain_and_valid=datasets.CIFAR10(root=\"data\", train=True, transform=train_transform, download=True)\n\ntrain_dataset=Subset(train_and_valid, train_indices)\nvalid_dataset=Subset(train_and_valid, valid_indices)\ntest_dataset=datasets.CIFAR10(root=\"data\", train=False, transform=test_transform, download=False)\n\ntrain_loader=DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=4)\n\nvalid_loader=DataLoader(dataset=valid_dataset, batch_size=batch_size, num_workers=4)\n\ntest_loader=DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=4)","execution_count":3,"outputs":[{"output_type":"stream","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6073273dd13d4ebbaa9060df50f688b7"}},"metadata":{}},{"output_type":"stream","text":"Extracting data/cifar-10-python.tar.gz to data\n","name":"stdout"}]},{"metadata":{"_uuid":"985147a4-c921-46b2-89d1-367dbe8fe294","_cell_guid":"a88f9d46-aa03-4759-ac8e-03cf64d03bd0","trusted":true},"cell_type":"code","source":"# Checking the dataset\nprint(\"Training Set:\\n\")\nfor images, labels in train_loader:\n    print(\"Image batch dimensions: \", images.shape)\n    print(\"Image label dimensions: \", labels.shape)\n    break\n\n# Checking the dataset\nprint(\"\\nValidation Set:\")\nfor images, labels in valid_loader:\n    print(\"Image batch dimensions: \", images.shape)\n    print(\"Image label dimensions: \", labels.shape)\n    break\n\n# Checking the dataset\nprint(\"\\nTest Set:\")\nfor images, labels in test_loader:\n    print(\"Image batch dimensions: \", images.shape)\n    print(\"Image label dimensions: \", labels.shape)\n    break","execution_count":4,"outputs":[{"output_type":"stream","text":"Training Set:\n\n\n\nImage batch dimensions:  torch.Size([256, 3, 64, 64])\nImage label dimensions:  torch.Size([256])\n\n\nValidation Set:\nImage batch dimensions:  torch.Size([256, 3, 64, 64])\nImage label dimensions:  torch.Size([256])\n\nTest Set:\nImage batch dimensions:  torch.Size([256, 3, 64, 64])\nImage label dimensions:  torch.Size([256])\n","name":"stdout"}]},{"metadata":{"_uuid":"cf97317d-aa8a-42a2-9f62-2da56b79a20b","_cell_guid":"5d7ed333-543b-4a41-bc0f-b7264ce61f78","trusted":true},"cell_type":"code","source":"# Model\nclass AlexNet(nn.Module):\n    def __init__(self, num_classes):\n        super(AlexNet, self).__init__()\n        self.features=nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True), \n            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n            )\n        \n        self.avgpool=nn.AdaptiveAvgPool2d((6, 6))\n        \n        self.classifier=nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(256*6*6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes)\n            )\n    \n    def forward(self, x):\n        x=self.features(x)\n        x=self.avgpool(x)\n        x=x.view(x.size(0), 256*6*6)\n        logits=self.classifier(x)\n        probas=F.softmax(logits, dim=1)\n        return logits, probas","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"3e431be8-7a5c-4aab-aecf-be25ee2277f5","_cell_guid":"1ec05c8e-6ebe-4c7a-880d-ac771c79396b","trusted":true},"cell_type":"code","source":"torch.manual_seed(random_seed)\nmodel=AlexNet(num_classes=num_classes)\nmodel.to(device)\n\noptimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"18eef0be-220d-43fb-b2aa-d017531070a1","_cell_guid":"461bbc47-8ef1-4e70-8600-878c50819d8c","trusted":true},"cell_type":"code","source":"# Training\ndef compute_accuracy(model, data_loader, device):\n    correct_pred, num_examples=0, 0\n    model.eval()\n    for i, (features, targets) in enumerate(data_loader):\n        \n        features=features.to(device)\n        targets=targets.to(device)\n        \n        logits, probas=model(features)\n        _, predicted_labels=torch.max(probas, 1)\n        num_examples+=targets.size(0)\n        assert predicted_labels.size()==targets.size()\n        correct_pred+=(predicted_labels==targets).sum()\n    return correct_pred.float()/num_examples*100\n\n\nstart_time=time.time()\ncost_list=[]\ntrain_acc_list, valid_acc_list=[], []\n\nfor epoch in range(num_epochs):\n    \n    model.train()\n    for batch_idx, (features, targets) in enumerate(train_loader):\n        \n        features=features.to(device)\n        targets=targets.to(device)\n        \n        # Forward and backprop\n        logits, probas=model(features)\n        cost=F.cross_entropy(logits, targets)\n        optimizer.zero_grad()\n        \n        cost.backward()\n        \n        # Update model parameters\n        optimizer.step()\n        \n        # ONLY FOR LOGGING\n        cost_list.append(cost.item())\n        if not batch_idx % 150:\n            print(\"Batch: %03d/%03d | Epoch: %03d/%03d | Cost: %.2f\" % (batch_idx, len(train_loader), epoch+1, num_epochs, cost))\n        \n    model.eval()\n    with torch.set_grad_enabled(False):\n\n        train_acc=compute_accuracy(model, train_loader, device)\n        valid_acc=compute_accuracy(model, valid_loader, device)\n\n        print(f'Epoch: {epoch+1:03d}/{num_epochs:03d}\\n'\n              f'Train ACC: {train_acc:.2f} | Validation ACC: {valid_acc:.2f}')\n        \n        train_acc_list.append(train_acc)\n        valid_acc_list.append(valid_acc)\n    \n    elapsed=(time.time()-start_time)/60\n    print(f'Time Elapsed: {elapsed:.2f} min')\n\nelapsed=(time.time()-start_time)/60\nprint(f'Total Training Time: {elapsed:.2f} min')","execution_count":7,"outputs":[{"output_type":"stream","text":"Batch: 000/188 | Epoch: 001/020 | Cost: 2.30\nBatch: 150/188 | Epoch: 001/020 | Cost: 1.74\nEpoch: 001/020\nTrain ACC: 35.74 | Validation ACC: 37.15\nTime Elapsed: 0.50 min\nBatch: 000/188 | Epoch: 002/020 | Cost: 1.65\nBatch: 150/188 | Epoch: 002/020 | Cost: 1.49\nEpoch: 002/020\nTrain ACC: 44.17 | Validation ACC: 43.40\nTime Elapsed: 1.01 min\nBatch: 000/188 | Epoch: 003/020 | Cost: 1.48\nBatch: 150/188 | Epoch: 003/020 | Cost: 1.30\nEpoch: 003/020\nTrain ACC: 52.15 | Validation ACC: 53.15\nTime Elapsed: 1.50 min\nBatch: 000/188 | Epoch: 004/020 | Cost: 1.21\nBatch: 150/188 | Epoch: 004/020 | Cost: 1.22\nEpoch: 004/020\nTrain ACC: 56.81 | Validation ACC: 56.80\nTime Elapsed: 2.01 min\nBatch: 000/188 | Epoch: 005/020 | Cost: 1.13\nBatch: 150/188 | Epoch: 005/020 | Cost: 1.14\nEpoch: 005/020\nTrain ACC: 58.57 | Validation ACC: 59.20\nTime Elapsed: 2.49 min\nBatch: 000/188 | Epoch: 006/020 | Cost: 1.07\nBatch: 150/188 | Epoch: 006/020 | Cost: 1.13\nEpoch: 006/020\nTrain ACC: 61.35 | Validation ACC: 61.55\nTime Elapsed: 3.00 min\nBatch: 000/188 | Epoch: 007/020 | Cost: 1.02\nBatch: 150/188 | Epoch: 007/020 | Cost: 1.02\nEpoch: 007/020\nTrain ACC: 60.72 | Validation ACC: 60.25\nTime Elapsed: 3.49 min\nBatch: 000/188 | Epoch: 008/020 | Cost: 1.00\nBatch: 150/188 | Epoch: 008/020 | Cost: 0.90\nEpoch: 008/020\nTrain ACC: 64.44 | Validation ACC: 62.05\nTime Elapsed: 4.00 min\nBatch: 000/188 | Epoch: 009/020 | Cost: 0.93\nBatch: 150/188 | Epoch: 009/020 | Cost: 0.81\nEpoch: 009/020\nTrain ACC: 67.43 | Validation ACC: 64.70\nTime Elapsed: 4.48 min\nBatch: 000/188 | Epoch: 010/020 | Cost: 0.85\nBatch: 150/188 | Epoch: 010/020 | Cost: 0.78\nEpoch: 010/020\nTrain ACC: 69.22 | Validation ACC: 64.15\nTime Elapsed: 4.99 min\nBatch: 000/188 | Epoch: 011/020 | Cost: 0.79\nBatch: 150/188 | Epoch: 011/020 | Cost: 0.67\nEpoch: 011/020\nTrain ACC: 72.17 | Validation ACC: 67.10\nTime Elapsed: 5.47 min\nBatch: 000/188 | Epoch: 012/020 | Cost: 0.69\nBatch: 150/188 | Epoch: 012/020 | Cost: 0.64\nEpoch: 012/020\nTrain ACC: 72.30 | Validation ACC: 67.70\nTime Elapsed: 5.98 min\nBatch: 000/188 | Epoch: 013/020 | Cost: 0.65\nBatch: 150/188 | Epoch: 013/020 | Cost: 0.62\nEpoch: 013/020\nTrain ACC: 72.88 | Validation ACC: 67.50\nTime Elapsed: 6.45 min\nBatch: 000/188 | Epoch: 014/020 | Cost: 0.65\nBatch: 150/188 | Epoch: 014/020 | Cost: 0.54\nEpoch: 014/020\nTrain ACC: 76.87 | Validation ACC: 69.30\nTime Elapsed: 6.96 min\nBatch: 000/188 | Epoch: 015/020 | Cost: 0.61\nBatch: 150/188 | Epoch: 015/020 | Cost: 0.54\nEpoch: 015/020\nTrain ACC: 77.50 | Validation ACC: 69.65\nTime Elapsed: 7.43 min\nBatch: 000/188 | Epoch: 016/020 | Cost: 0.58\nBatch: 150/188 | Epoch: 016/020 | Cost: 0.54\nEpoch: 016/020\nTrain ACC: 78.29 | Validation ACC: 69.40\nTime Elapsed: 7.93 min\nBatch: 000/188 | Epoch: 017/020 | Cost: 0.55\nBatch: 150/188 | Epoch: 017/020 | Cost: 0.57\nEpoch: 017/020\nTrain ACC: 80.98 | Validation ACC: 71.65\nTime Elapsed: 8.40 min\nBatch: 000/188 | Epoch: 018/020 | Cost: 0.48\nBatch: 150/188 | Epoch: 018/020 | Cost: 0.50\nEpoch: 018/020\nTrain ACC: 81.70 | Validation ACC: 70.50\nTime Elapsed: 8.90 min\nBatch: 000/188 | Epoch: 019/020 | Cost: 0.48\nBatch: 150/188 | Epoch: 019/020 | Cost: 0.47\nEpoch: 019/020\nTrain ACC: 82.81 | Validation ACC: 71.95\nTime Elapsed: 9.38 min\nBatch: 000/188 | Epoch: 020/020 | Cost: 0.43\nBatch: 150/188 | Epoch: 020/020 | Cost: 0.42\nEpoch: 020/020\nTrain ACC: 82.00 | Validation ACC: 69.60\nTime Elapsed: 9.89 min\nTotal Training Time: 9.89 min\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\nwith torch.set_grad_enabled(False): # save memory during inference\n    test_acc=compute_accuracy(model=model, data_loader=test_loader, device=device)\n    valid_acc=compute_accuracy(model=model, data_loader=valid_loader, device=device)\n\nprint(\"Valid Accuracy: %.2f%% || Test Accuracy: %.2f%%\" % (valid_acc, test_acc))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}