{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_sample_ResNet34.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNf+AcevKOsjOZL2JIl2HtE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal-burman/PyTorch-Architectures/blob/master/modeling_ResNet/test_sample_ResNet34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsvI8RnQYDJC",
        "outputId": "a6d87308-8361-4927-f169-ced68230fbf1"
      },
      "source": [
        "! git clone https://github.com/vishal-burman/PyTorch-Architectures.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorch-Architectures'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (239/239), done.\u001b[K\n",
            "remote: Compressing objects: 100% (155/155), done.\u001b[K\n",
            "remote: Total 1177 (delta 116), reused 156 (delta 60), pack-reused 938\u001b[K\n",
            "Receiving objects: 100% (1177/1177), 8.51 MiB | 23.36 MiB/s, done.\n",
            "Resolving deltas: 100% (687/687), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbnOTnp2YMdU",
        "outputId": "1d75daf1-0fa2-4f5d-c829-f6d3c2bc57ab"
      },
      "source": [
        "%cd PyTorch-Architectures/modeling_ResNet/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PyTorch-Architectures/modeling_ResNet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH7sW6joYWP5"
      },
      "source": [
        "import time\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "from torchvision import datasets, transforms\r\n",
        "from model import ResNet, BasicBlock\r\n",
        "\r\n",
        "if torch.cuda.is_available():\r\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqhGNzQuZ68b"
      },
      "source": [
        "# Hyperparameters\r\n",
        "\r\n",
        "RANDOM_SEED = 1\r\n",
        "LEARNING_RATE = 0.001\r\n",
        "BATCH_SIZE = 128\r\n",
        "NUM_EPOCHS = 10\r\n",
        "\r\n",
        "NUM_FEATURES = 28 * 28\r\n",
        "NUM_CLASSES = 10\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "grayscale = True"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGwVHNUdaU9c"
      },
      "source": [
        "# MNIST Dataset\r\n",
        "\r\n",
        "train_dataset = datasets.MNIST(\r\n",
        "    root=\"data\",\r\n",
        "    train=True,\r\n",
        "    transform=transforms.ToTensor(),\r\n",
        "    download=True,\r\n",
        ")\r\n",
        "test_dataset = datasets.MNIST(\r\n",
        "    root=\"data\",\r\n",
        "    train=False,\r\n",
        "    transform=transforms.ToTensor(),\r\n",
        ")\r\n",
        "\r\n",
        "train_loader = DataLoader(\r\n",
        "    dataset=train_dataset,\r\n",
        "    batch_size=BATCH_SIZE,\r\n",
        "    shuffle=True,\r\n",
        ")\r\n",
        "test_loader = DataLoader(\r\n",
        "    dataset=test_dataset,\r\n",
        "    batch_size=BATCH_SIZE,\r\n",
        "    shuffle=False,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfbbudQKdAY0",
        "outputId": "bf2288a5-ad3c-4de3-ff66-3ed78bcfd3be"
      },
      "source": [
        "# Checking the dataset\r\n",
        "for images, labels in train_loader:\r\n",
        "  print(\"Image Batch Dimensions: \", images.shape)\r\n",
        "  print(\"Label Batch Dimensions: \", labels.shape)\r\n",
        "  break"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Batch Dimensions:  torch.Size([128, 1, 28, 28])\n",
            "Label Batch Dimensions:  torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z9WCByTdN-D"
      },
      "source": [
        "def resnet34(NUM_CLASSES):\r\n",
        "  model = ResNet(\r\n",
        "      block=BasicBlock,\r\n",
        "      layers=[3, 4, 6, 3],\r\n",
        "      num_classes=NUM_CLASSES,\r\n",
        "      grayscale=grayscale,\r\n",
        "  )\r\n",
        "  return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIzTivsBdlCc",
        "outputId": "465c5867-99c1-484d-db9a-fa01661c9ff4"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\r\n",
        "model = resnet34(NUM_CLASSES)\r\n",
        "model.to(device)\r\n",
        "\r\n",
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "print(\"Trainable Parameters: \", params)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable Parameters:  21283530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFR2yzlceAaR"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQEX8af3e0de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ab9aa3-9f68-4b0c-ab57-bddbe5a83e63"
      },
      "source": [
        "def compute_accuracy(model, data_loader, device):\r\n",
        "  correct_pred, num_examples = 0, 0\r\n",
        "  for features, targets in data_loader:\r\n",
        "    features = features.to(device)\r\n",
        "    targets = targets.to(device)\r\n",
        "    logits, probas = model(features)\r\n",
        "    _, predicted_labels = torch.max(probas, 1)\r\n",
        "    correct_pred += (predicted_labels == targets).sum()\r\n",
        "    num_examples += targets.size(0)\r\n",
        "  return correct_pred / num_examples * 100\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "for epoch in range(NUM_EPOCHS):\r\n",
        "  model.train()\r\n",
        "  for idx, (features, targets) in enumerate(train_loader):\r\n",
        "    features = features.to(device)\r\n",
        "    targets = targets.to(device)\r\n",
        "\r\n",
        "    logits, probas = model(features)\r\n",
        "    loss = F.cross_entropy(logits, targets)\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    # LOGGING\r\n",
        "    if idx % 50 == 0:\r\n",
        "      print(\"Batch: %04d/%04d | Epoch: %04d/%04d | Cost: %.4f\" % (idx, len(train_loader), epoch+1, NUM_EPOCHS, loss.item()))\r\n",
        "  \r\n",
        "  model.eval()\r\n",
        "  with torch.set_grad_enabled(False):\r\n",
        "    print('Epoch: %04d/%04d | Train Acc: %.3f' % (epoch+1, NUM_EPOCHS, compute_accuracy(model, train_loader, device)))\r\n",
        "  print('Epoch Elapsed Time: %.2f min' % ((time.time() - start_time) / 60))\r\n",
        "print('Total Training Time: %.2f min' % ((time.time() - start_time) / 60))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch: 0000/0469 | Epoch: 0001/0010 | Cost: 2.5827\n",
            "Batch: 0050/0469 | Epoch: 0001/0010 | Cost: 0.1939\n",
            "Batch: 0100/0469 | Epoch: 0001/0010 | Cost: 0.2451\n",
            "Batch: 0150/0469 | Epoch: 0001/0010 | Cost: 0.0646\n",
            "Batch: 0200/0469 | Epoch: 0001/0010 | Cost: 0.0703\n",
            "Batch: 0250/0469 | Epoch: 0001/0010 | Cost: 0.1670\n",
            "Batch: 0300/0469 | Epoch: 0001/0010 | Cost: 0.0391\n",
            "Batch: 0350/0469 | Epoch: 0001/0010 | Cost: 0.1063\n",
            "Batch: 0400/0469 | Epoch: 0001/0010 | Cost: 0.1074\n",
            "Batch: 0450/0469 | Epoch: 0001/0010 | Cost: 0.1380\n",
            "Epoch: 0001/0010 | Train Acc: 98.162\n",
            "Epoch Elapsed Time: 0.58 min\n",
            "Batch: 0000/0469 | Epoch: 0002/0010 | Cost: 0.0825\n",
            "Batch: 0050/0469 | Epoch: 0002/0010 | Cost: 0.0354\n",
            "Batch: 0100/0469 | Epoch: 0002/0010 | Cost: 0.0128\n",
            "Batch: 0150/0469 | Epoch: 0002/0010 | Cost: 0.0363\n",
            "Batch: 0200/0469 | Epoch: 0002/0010 | Cost: 0.0160\n",
            "Batch: 0250/0469 | Epoch: 0002/0010 | Cost: 0.0192\n",
            "Batch: 0300/0469 | Epoch: 0002/0010 | Cost: 0.0859\n",
            "Batch: 0350/0469 | Epoch: 0002/0010 | Cost: 0.1351\n",
            "Batch: 0400/0469 | Epoch: 0002/0010 | Cost: 0.0474\n",
            "Batch: 0450/0469 | Epoch: 0002/0010 | Cost: 0.0470\n",
            "Epoch: 0002/0010 | Train Acc: 98.823\n",
            "Epoch Elapsed Time: 1.12 min\n",
            "Batch: 0000/0469 | Epoch: 0003/0010 | Cost: 0.0898\n",
            "Batch: 0050/0469 | Epoch: 0003/0010 | Cost: 0.0351\n",
            "Batch: 0100/0469 | Epoch: 0003/0010 | Cost: 0.0262\n",
            "Batch: 0150/0469 | Epoch: 0003/0010 | Cost: 0.0164\n",
            "Batch: 0200/0469 | Epoch: 0003/0010 | Cost: 0.1184\n",
            "Batch: 0250/0469 | Epoch: 0003/0010 | Cost: 0.0265\n",
            "Batch: 0300/0469 | Epoch: 0003/0010 | Cost: 0.0180\n",
            "Batch: 0350/0469 | Epoch: 0003/0010 | Cost: 0.0926\n",
            "Batch: 0400/0469 | Epoch: 0003/0010 | Cost: 0.0535\n",
            "Batch: 0450/0469 | Epoch: 0003/0010 | Cost: 0.0032\n",
            "Epoch: 0003/0010 | Train Acc: 98.985\n",
            "Epoch Elapsed Time: 1.66 min\n",
            "Batch: 0000/0469 | Epoch: 0004/0010 | Cost: 0.0202\n",
            "Batch: 0050/0469 | Epoch: 0004/0010 | Cost: 0.0014\n",
            "Batch: 0100/0469 | Epoch: 0004/0010 | Cost: 0.0091\n",
            "Batch: 0150/0469 | Epoch: 0004/0010 | Cost: 0.0403\n",
            "Batch: 0200/0469 | Epoch: 0004/0010 | Cost: 0.0513\n",
            "Batch: 0250/0469 | Epoch: 0004/0010 | Cost: 0.1115\n",
            "Batch: 0300/0469 | Epoch: 0004/0010 | Cost: 0.0070\n",
            "Batch: 0350/0469 | Epoch: 0004/0010 | Cost: 0.0088\n",
            "Batch: 0400/0469 | Epoch: 0004/0010 | Cost: 0.0831\n",
            "Batch: 0450/0469 | Epoch: 0004/0010 | Cost: 0.1160\n",
            "Epoch: 0004/0010 | Train Acc: 98.810\n",
            "Epoch Elapsed Time: 2.22 min\n",
            "Batch: 0000/0469 | Epoch: 0005/0010 | Cost: 0.0064\n",
            "Batch: 0050/0469 | Epoch: 0005/0010 | Cost: 0.0131\n",
            "Batch: 0100/0469 | Epoch: 0005/0010 | Cost: 0.0431\n",
            "Batch: 0150/0469 | Epoch: 0005/0010 | Cost: 0.0457\n",
            "Batch: 0200/0469 | Epoch: 0005/0010 | Cost: 0.0267\n",
            "Batch: 0250/0469 | Epoch: 0005/0010 | Cost: 0.0017\n",
            "Batch: 0300/0469 | Epoch: 0005/0010 | Cost: 0.0016\n",
            "Batch: 0350/0469 | Epoch: 0005/0010 | Cost: 0.0161\n",
            "Batch: 0400/0469 | Epoch: 0005/0010 | Cost: 0.0317\n",
            "Batch: 0450/0469 | Epoch: 0005/0010 | Cost: 0.0115\n",
            "Epoch: 0005/0010 | Train Acc: 98.982\n",
            "Epoch Elapsed Time: 2.80 min\n",
            "Batch: 0000/0469 | Epoch: 0006/0010 | Cost: 0.0686\n",
            "Batch: 0050/0469 | Epoch: 0006/0010 | Cost: 0.0077\n",
            "Batch: 0100/0469 | Epoch: 0006/0010 | Cost: 0.0051\n",
            "Batch: 0150/0469 | Epoch: 0006/0010 | Cost: 0.0581\n",
            "Batch: 0200/0469 | Epoch: 0006/0010 | Cost: 0.0182\n",
            "Batch: 0250/0469 | Epoch: 0006/0010 | Cost: 0.0710\n",
            "Batch: 0300/0469 | Epoch: 0006/0010 | Cost: 0.0353\n",
            "Batch: 0350/0469 | Epoch: 0006/0010 | Cost: 0.0361\n",
            "Batch: 0400/0469 | Epoch: 0006/0010 | Cost: 0.0152\n",
            "Batch: 0450/0469 | Epoch: 0006/0010 | Cost: 0.0509\n",
            "Epoch: 0006/0010 | Train Acc: 98.520\n",
            "Epoch Elapsed Time: 3.37 min\n",
            "Batch: 0000/0469 | Epoch: 0007/0010 | Cost: 0.0358\n",
            "Batch: 0050/0469 | Epoch: 0007/0010 | Cost: 0.0005\n",
            "Batch: 0100/0469 | Epoch: 0007/0010 | Cost: 0.0105\n",
            "Batch: 0150/0469 | Epoch: 0007/0010 | Cost: 0.0059\n",
            "Batch: 0200/0469 | Epoch: 0007/0010 | Cost: 0.0393\n",
            "Batch: 0250/0469 | Epoch: 0007/0010 | Cost: 0.0187\n",
            "Batch: 0300/0469 | Epoch: 0007/0010 | Cost: 0.0393\n",
            "Batch: 0350/0469 | Epoch: 0007/0010 | Cost: 0.0025\n",
            "Batch: 0400/0469 | Epoch: 0007/0010 | Cost: 0.0326\n",
            "Batch: 0450/0469 | Epoch: 0007/0010 | Cost: 0.0553\n",
            "Epoch: 0007/0010 | Train Acc: 99.083\n",
            "Epoch Elapsed Time: 3.95 min\n",
            "Batch: 0000/0469 | Epoch: 0008/0010 | Cost: 0.0082\n",
            "Batch: 0050/0469 | Epoch: 0008/0010 | Cost: 0.0082\n",
            "Batch: 0100/0469 | Epoch: 0008/0010 | Cost: 0.0027\n",
            "Batch: 0150/0469 | Epoch: 0008/0010 | Cost: 0.0124\n",
            "Batch: 0200/0469 | Epoch: 0008/0010 | Cost: 0.0180\n",
            "Batch: 0250/0469 | Epoch: 0008/0010 | Cost: 0.0330\n",
            "Batch: 0300/0469 | Epoch: 0008/0010 | Cost: 0.0079\n",
            "Batch: 0350/0469 | Epoch: 0008/0010 | Cost: 0.0088\n",
            "Batch: 0400/0469 | Epoch: 0008/0010 | Cost: 0.0113\n",
            "Batch: 0450/0469 | Epoch: 0008/0010 | Cost: 0.0211\n",
            "Epoch: 0008/0010 | Train Acc: 99.575\n",
            "Epoch Elapsed Time: 4.53 min\n",
            "Batch: 0000/0469 | Epoch: 0009/0010 | Cost: 0.0273\n",
            "Batch: 0050/0469 | Epoch: 0009/0010 | Cost: 0.0019\n",
            "Batch: 0100/0469 | Epoch: 0009/0010 | Cost: 0.0187\n",
            "Batch: 0150/0469 | Epoch: 0009/0010 | Cost: 0.0407\n",
            "Batch: 0200/0469 | Epoch: 0009/0010 | Cost: 0.0349\n",
            "Batch: 0250/0469 | Epoch: 0009/0010 | Cost: 0.0385\n",
            "Batch: 0300/0469 | Epoch: 0009/0010 | Cost: 0.0032\n",
            "Batch: 0350/0469 | Epoch: 0009/0010 | Cost: 0.0103\n",
            "Batch: 0400/0469 | Epoch: 0009/0010 | Cost: 0.0082\n",
            "Batch: 0450/0469 | Epoch: 0009/0010 | Cost: 0.0191\n",
            "Epoch: 0009/0010 | Train Acc: 99.350\n",
            "Epoch Elapsed Time: 5.11 min\n",
            "Batch: 0000/0469 | Epoch: 0010/0010 | Cost: 0.0630\n",
            "Batch: 0050/0469 | Epoch: 0010/0010 | Cost: 0.0005\n",
            "Batch: 0100/0469 | Epoch: 0010/0010 | Cost: 0.0817\n",
            "Batch: 0150/0469 | Epoch: 0010/0010 | Cost: 0.0400\n",
            "Batch: 0200/0469 | Epoch: 0010/0010 | Cost: 0.0639\n",
            "Batch: 0250/0469 | Epoch: 0010/0010 | Cost: 0.0011\n",
            "Batch: 0300/0469 | Epoch: 0010/0010 | Cost: 0.0027\n",
            "Batch: 0350/0469 | Epoch: 0010/0010 | Cost: 0.0937\n",
            "Batch: 0400/0469 | Epoch: 0010/0010 | Cost: 0.0280\n",
            "Batch: 0450/0469 | Epoch: 0010/0010 | Cost: 0.0833\n",
            "Epoch: 0010/0010 | Train Acc: 99.237\n",
            "Epoch Elapsed Time: 5.69 min\n",
            "Total Training Time: 5.69 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxt4IDPMxAAM",
        "outputId": "35efbf32-3064-4e71-a899-79f59f55557c"
      },
      "source": [
        "model.eval()\r\n",
        "with torch.set_grad_enabled(False):\r\n",
        "  print('Test Accuracy: %.2f' % (compute_accuracy(model, test_loader, device)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 98.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0M09zvryhVW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}