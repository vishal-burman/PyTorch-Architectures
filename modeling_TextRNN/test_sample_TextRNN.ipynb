{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_sample_TextRNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOHO7l4nqqkE5ZZybkTve13",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal-burman/PyTorch-Architectures/blob/master/modeling_TextRNN/test_sample_TextRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iyvxaf-lPbbu"
      },
      "source": [
        "! pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwk57RyHPAuD"
      },
      "source": [
        "# ! rm -rf PyTorch-Architectures/\n",
        "! git clone https://github.com/vishal-burman/PyTorch-Architectures.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLoBDVATSOmY",
        "outputId": "a4b20d35-bf55-43a4-ec5b-d01d14f526ed"
      },
      "source": [
        "%cd PyTorch-Architectures/modeling_TextRNN/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PyTorch-Architectures/modeling_TextRNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju6wV2fMPMai",
        "outputId": "739a3458-7f64-41eb-9fe4-2f7e46a930b4"
      },
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from model import TextRNN\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset('quora')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset quora (/root/.cache/huggingface/datasets/quora/default/0.0.0/2be517cf0ac6de94b77a103a36b141347a13f40637fbebaccb56ddbe397876be)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3n80GKLSZ76"
      },
      "source": [
        "sentences = []\n",
        "for sample in dataset['train']:\n",
        "  if len(sentences) == 10000:\n",
        "    break\n",
        "  sent = sample['questions']['text'][0]\n",
        "  if len(sent.split()) >= 4:\n",
        "    sentences.append(sent)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onUSagttSpxi",
        "outputId": "20687408-5a1b-4b58-a597-6d53db6cfaec"
      },
      "source": [
        "word_list = ' '.join(sentences).split()\n",
        "word_list = list(set(word_list))\n",
        "\n",
        "word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "number_dict = {i: w for i, w in enumerate(word_list)}\n",
        "n_class = len(word_dict)\n",
        "print('Vocabulary Size: ', n_class)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size:  18198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6LFLYeESv54"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, list_sentences, max_inp_length=4):\n",
        "    self.list_sentences = list_sentences\n",
        "    self.max_inp_length = max_inp_length\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.list_sentences)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "    sentences = self.list_sentences[idx]\n",
        "    tokens = self.tokenize_into_tensors(sentences)\n",
        "    return {\n",
        "        'input_batch': tokens['inp_batch'],\n",
        "        'target_batch': tokens['tgt_batch'],\n",
        "    }\n",
        "  \n",
        "  def tokenize_into_tensors(self, sentence):\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "    word = sentence.split()\n",
        "    word = word[:self.max_inp_length]\n",
        "    input_tokens = [word_dict[n] for n in word[:-1]]\n",
        "    target_tokens = word_dict[word[-1]]\n",
        "    input_batch.append(input_tokens)\n",
        "    target_batch.append(target_tokens)\n",
        "    return {\n",
        "        'inp_batch': torch.tensor(input_batch),\n",
        "        'tgt_batch': torch.tensor(target_batch),\n",
        "    }"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdHrRhMcSywq",
        "outputId": "c9eaeed9-92ea-4841-ed74-ebe24e1ee499"
      },
      "source": [
        "lim = 90 * len(sentences) // 100\n",
        "train_sentences = sentences[:lim]\n",
        "valid_sentences = sentences[lim:]\n",
        "print('Train Samples: ', len(train_sentences))\n",
        "print('Valid Samples: ', len(valid_sentences))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Samples:  9000\n",
            "Valid Samples:  1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0hYOgZ-S1XL"
      },
      "source": [
        "train_dataset = CustomDataset(train_sentences, max_inp_length=4)\n",
        "valid_dataset = CustomDataset(valid_sentences, max_inp_length=4)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83tCpUrIS4wu"
      },
      "source": [
        "# Hyperparameters\n",
        "VOCAB_SIZE = n_class\n",
        "EMBEDDING_SIZE = 32\n",
        "HIDDEN_SIZE = 100\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 10"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GTd7_1BS8U_",
        "outputId": "71ab8747-a606-4d09-a867-88d78305d64a"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = TextRNN(vocab_size=VOCAB_SIZE, embedding_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE)\n",
        "model.to(device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextRNN(\n",
              "  (embedding): Embedding(18198, 32)\n",
              "  (rnn): RNN(32, 100)\n",
              "  (W): Linear(in_features=100, out_features=18198, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9-oXrLbToXu",
        "outputId": "9df6dc31-b758-4813-e93e-cee377ca78af"
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Sanity check DataLoader\n",
        "for sample in train_loader:\n",
        "  assert sample['input_batch'].squeeze(1).dim() == 2\n",
        "  assert sample['target_batch'].dim() == 2\n",
        "  break\n",
        "\n",
        "print('Length of Train Loader: ', len(train_loader))\n",
        "print('Length of Valid Loader: ', len(valid_loader))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Train Loader:  282\n",
            "Length of Valid Loader:  32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucGGkNPeTsCZ"
      },
      "source": [
        "# Sanity check model outputs\n",
        "model.eval()\n",
        "with torch.set_grad_enabled(False):\n",
        "  outputs = model(sample['input_batch'].squeeze(1))\n",
        "  assert outputs.size(1) == n_class"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE3oSQL9XCtW"
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axtOLO9VXFtZ",
        "outputId": "56debe6e-5dea-45b4-a0d3-4397b54ba8d6"
      },
      "source": [
        "def compute_loss(model, data_loader, device):\n",
        "  list_loss = []\n",
        "  with torch.set_grad_enabled(False):\n",
        "    for sample in data_loader:\n",
        "      features = sample['input_batch'].squeeze(1)\n",
        "      targets = sample['target_batch'].squeeze(1)\n",
        "\n",
        "      logits = model(features)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "      list_loss.append(loss.item())\n",
        "  return torch.tensor(list_loss).mean()\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(EPOCHS):\n",
        "  model.train()\n",
        "  for idx, sample in enumerate(train_loader):\n",
        "    features = sample['input_batch'].squeeze(1)\n",
        "    targets = sample['target_batch'].squeeze(1)\n",
        "\n",
        "    logits = model(features)\n",
        "    loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # LOGGING\n",
        "    if idx % 50 == 0:\n",
        "      print('Batch: %04d/%04d || Epoch: %04d/%04d || Loss: %.2f' % (idx, len(train_loader), epoch+1, EPOCHS, loss.item()))\n",
        "  \n",
        "  model.eval()\n",
        "  with torch.set_grad_enabled(False):\n",
        "    train_loss = compute_loss(model, train_loader, device)\n",
        "    valid_loss = compute_loss(model, valid_loader, device)\n",
        "\n",
        "    print('Train Loss: %.2f' % (train_loss.item()))\n",
        "    print('Valid Loss: %.2f' % (valid_loss.item()))\n",
        "  epoch_elapsed_time = (time.time() - start_time) / 60\n",
        "  print('Epoch Elapsed Time: %.2f min' % (epoch_elapsed_time))\n",
        "total_training_time = (time.time() - start_time) / 60\n",
        "print('Total Training Time: %.2f min' % (total_training_time))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch: 0000/0282 || Epoch: 0001/0010 || Loss: 9.95\n",
            "Batch: 0050/0282 || Epoch: 0001/0010 || Loss: 9.90\n",
            "Batch: 0100/0282 || Epoch: 0001/0010 || Loss: 9.85\n",
            "Batch: 0150/0282 || Epoch: 0001/0010 || Loss: 9.86\n",
            "Batch: 0200/0282 || Epoch: 0001/0010 || Loss: 9.85\n",
            "Batch: 0250/0282 || Epoch: 0001/0010 || Loss: 9.77\n",
            "Train Loss: 9.82\n",
            "Valid Loss: 9.81\n",
            "Epoch Elapsed Time: 0.14 min\n",
            "Batch: 0000/0282 || Epoch: 0002/0010 || Loss: 9.86\n",
            "Batch: 0050/0282 || Epoch: 0002/0010 || Loss: 9.80\n",
            "Batch: 0100/0282 || Epoch: 0002/0010 || Loss: 9.83\n",
            "Batch: 0150/0282 || Epoch: 0002/0010 || Loss: 9.80\n",
            "Batch: 0200/0282 || Epoch: 0002/0010 || Loss: 9.83\n",
            "Batch: 0250/0282 || Epoch: 0002/0010 || Loss: 9.78\n",
            "Train Loss: 9.79\n",
            "Valid Loss: 9.78\n",
            "Epoch Elapsed Time: 0.27 min\n",
            "Batch: 0000/0282 || Epoch: 0003/0010 || Loss: 9.77\n",
            "Batch: 0050/0282 || Epoch: 0003/0010 || Loss: 9.80\n",
            "Batch: 0100/0282 || Epoch: 0003/0010 || Loss: 9.81\n",
            "Batch: 0150/0282 || Epoch: 0003/0010 || Loss: 9.73\n",
            "Batch: 0200/0282 || Epoch: 0003/0010 || Loss: 9.73\n",
            "Batch: 0250/0282 || Epoch: 0003/0010 || Loss: 9.72\n",
            "Train Loss: 9.75\n",
            "Valid Loss: 9.75\n",
            "Epoch Elapsed Time: 0.40 min\n",
            "Batch: 0000/0282 || Epoch: 0004/0010 || Loss: 9.76\n",
            "Batch: 0050/0282 || Epoch: 0004/0010 || Loss: 9.71\n",
            "Batch: 0100/0282 || Epoch: 0004/0010 || Loss: 9.74\n",
            "Batch: 0150/0282 || Epoch: 0004/0010 || Loss: 9.70\n",
            "Batch: 0200/0282 || Epoch: 0004/0010 || Loss: 9.62\n",
            "Batch: 0250/0282 || Epoch: 0004/0010 || Loss: 9.68\n",
            "Train Loss: 9.71\n",
            "Valid Loss: 9.71\n",
            "Epoch Elapsed Time: 0.54 min\n",
            "Batch: 0000/0282 || Epoch: 0005/0010 || Loss: 9.75\n",
            "Batch: 0050/0282 || Epoch: 0005/0010 || Loss: 9.75\n",
            "Batch: 0100/0282 || Epoch: 0005/0010 || Loss: 9.61\n",
            "Batch: 0150/0282 || Epoch: 0005/0010 || Loss: 9.70\n",
            "Batch: 0200/0282 || Epoch: 0005/0010 || Loss: 9.73\n",
            "Batch: 0250/0282 || Epoch: 0005/0010 || Loss: 9.62\n",
            "Train Loss: 9.68\n",
            "Valid Loss: 9.68\n",
            "Epoch Elapsed Time: 0.67 min\n",
            "Batch: 0000/0282 || Epoch: 0006/0010 || Loss: 9.78\n",
            "Batch: 0050/0282 || Epoch: 0006/0010 || Loss: 9.69\n",
            "Batch: 0100/0282 || Epoch: 0006/0010 || Loss: 9.56\n",
            "Batch: 0150/0282 || Epoch: 0006/0010 || Loss: 9.63\n",
            "Batch: 0200/0282 || Epoch: 0006/0010 || Loss: 9.69\n",
            "Batch: 0250/0282 || Epoch: 0006/0010 || Loss: 9.73\n",
            "Train Loss: 9.64\n",
            "Valid Loss: 9.64\n",
            "Epoch Elapsed Time: 0.80 min\n",
            "Batch: 0000/0282 || Epoch: 0007/0010 || Loss: 9.74\n",
            "Batch: 0050/0282 || Epoch: 0007/0010 || Loss: 9.52\n",
            "Batch: 0100/0282 || Epoch: 0007/0010 || Loss: 9.70\n",
            "Batch: 0150/0282 || Epoch: 0007/0010 || Loss: 9.38\n",
            "Batch: 0200/0282 || Epoch: 0007/0010 || Loss: 9.59\n",
            "Batch: 0250/0282 || Epoch: 0007/0010 || Loss: 9.67\n",
            "Train Loss: 9.60\n",
            "Valid Loss: 9.60\n",
            "Epoch Elapsed Time: 0.94 min\n",
            "Batch: 0000/0282 || Epoch: 0008/0010 || Loss: 9.41\n",
            "Batch: 0050/0282 || Epoch: 0008/0010 || Loss: 9.41\n",
            "Batch: 0100/0282 || Epoch: 0008/0010 || Loss: 9.56\n",
            "Batch: 0150/0282 || Epoch: 0008/0010 || Loss: 9.65\n",
            "Batch: 0200/0282 || Epoch: 0008/0010 || Loss: 9.44\n",
            "Batch: 0250/0282 || Epoch: 0008/0010 || Loss: 9.53\n",
            "Train Loss: 9.55\n",
            "Valid Loss: 9.56\n",
            "Epoch Elapsed Time: 1.07 min\n",
            "Batch: 0000/0282 || Epoch: 0009/0010 || Loss: 9.46\n",
            "Batch: 0050/0282 || Epoch: 0009/0010 || Loss: 9.41\n",
            "Batch: 0100/0282 || Epoch: 0009/0010 || Loss: 9.62\n",
            "Batch: 0150/0282 || Epoch: 0009/0010 || Loss: 9.63\n",
            "Batch: 0200/0282 || Epoch: 0009/0010 || Loss: 9.59\n",
            "Batch: 0250/0282 || Epoch: 0009/0010 || Loss: 9.76\n",
            "Train Loss: 9.51\n",
            "Valid Loss: 9.51\n",
            "Epoch Elapsed Time: 1.20 min\n",
            "Batch: 0000/0282 || Epoch: 0010/0010 || Loss: 9.39\n",
            "Batch: 0050/0282 || Epoch: 0010/0010 || Loss: 9.47\n",
            "Batch: 0100/0282 || Epoch: 0010/0010 || Loss: 9.55\n",
            "Batch: 0150/0282 || Epoch: 0010/0010 || Loss: 9.49\n",
            "Batch: 0200/0282 || Epoch: 0010/0010 || Loss: 9.09\n",
            "Batch: 0250/0282 || Epoch: 0010/0010 || Loss: 9.69\n",
            "Train Loss: 9.45\n",
            "Valid Loss: 9.46\n",
            "Epoch Elapsed Time: 1.33 min\n",
            "Total Training Time: 1.33 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OdVsdVUXLWH",
        "outputId": "2a4cb085-f80b-443e-aa44-588b2b9f812a"
      },
      "source": [
        "model.eval()\n",
        "with torch.set_grad_enabled(False):\n",
        "  text = \"Is there any\".split()\n",
        "  input_tokens = [word_dict[n] for n in text]\n",
        "  input_tokens = torch.tensor(input_tokens).unsqueeze(0)\n",
        "  logits = model(input_tokens)\n",
        "  probas = F.softmax(logits, dim=1)\n",
        "  _, predicted_word_idx = torch.max(probas, 1)\n",
        "  print('Your input --> ', ' '.join(text))\n",
        "  print('Predicted next token --> ', number_dict[predicted_word_idx.item()])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your input -->  Is there any\n",
            "Predicted next token -->  Salesforce?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "botjVU8lXhVm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}