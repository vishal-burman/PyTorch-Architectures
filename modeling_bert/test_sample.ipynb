{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "086whqMNZoOW",
    "outputId": "486f8a66-7288-47ea-adcc-9eb0fa283522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep  8 01:49:00 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGjacpdN4pe6"
   },
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "k-MUtCHC4wYZ",
    "outputId": "e7f1854d-e13a-4784-a0bd-0a5e515d33a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'PyTorch-Architectures'...\n",
      "remote: Enumerating objects: 242, done.\u001b[K\n",
      "remote: Counting objects: 100% (242/242), done.\u001b[K\n",
      "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
      "remote: Total 242 (delta 154), reused 150 (delta 78), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (242/242), 57.22 KiB | 332.00 KiB/s, done.\n",
      "Resolving deltas: 100% (154/154), done.\n"
     ]
    }
   ],
   "source": [
    "#! rm -rf PyTorch-Architectures/\n",
    "! git clone https://github.com/vishal-burman/PyTorch-Architectures.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQgMhF8E5RAF"
   },
   "outputs": [],
   "source": [
    "! cp /content/drive/'My Drive'/dataset.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2GnP4BTA8DD5"
   },
   "outputs": [],
   "source": [
    "! cp dataset.csv PyTorch-Architectures/modeling_bert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yRlSBeNM8aEO",
    "outputId": "2bcb811f-be2a-429b-dd0f-61d6c82a69ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/PyTorch-Architectures/modeling_bert\n"
     ]
    }
   ],
   "source": [
    "%cd PyTorch-Architectures/modeling_bert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "fa0cb2dd551a44e18b2068a3f6f8851a",
      "9d2f8a72ca3c4cef855020daf4759d23",
      "2817a859bd674b3cbcee99c379a5d976",
      "fa0f7a7fe2d3417fa63daeaecf93128e",
      "c324ce2d0b674faaa5459d39642cd226",
      "18ac6ad4fd2f485aa244aaf7508129d5",
      "9191a1268f1a468d99cb0724f084ae20",
      "b26c7cd3be024779980b4f5c925acdda"
     ]
    },
    "colab_type": "code",
    "id": "I_6mzxsj5b5p",
    "outputId": "f06c9f74-065d-4d6d-d8eb-d10926c030eb"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "from config_bert import BertConfig\n",
    "config = BertConfig()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7veKShFA7uuk"
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Sample data code\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.train_list = []\n",
    "        self.label_list = []\n",
    "        self.build()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ids = self.train_list[index]['input_ids']\n",
    "        mask = self.train_list[index]['attention_mask']\n",
    "        target = self.label_list[index]\n",
    "\n",
    "        return{\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(ids, dtype=torch.long),\n",
    "                'target': torch.tensor(target, dtype=torch.long).unsqueeze(0)\n",
    "                }\n",
    "\n",
    "    def build(self):\n",
    "        for t, l in zip(self.texts, self.labels):\n",
    "            self.train_list.append(tokenizer(t, max_length=128, pad_to_max_length=True, truncation=True))\n",
    "            self.label_list.append(l)\n",
    "##########################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "7RVFP3DJ5pPu",
    "outputId": "d9344be9-dd56-437d-d402-b344b342d79a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Conversion Done!!\n",
      "Time Taken =  3.045784366130829\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "with open(\"dataset.csv\", \"r\") as file_1:\n",
    "    reader = csv.reader(file_1)\n",
    "    for line in reader:\n",
    "        texts.append(line[0].strip())\n",
    "        labels.append(line[1].strip())\n",
    "\n",
    "texts = texts[1:]\n",
    "labels = labels[1:]\n",
    "\n",
    "labels = [1 if label == \"positive\" else 0 for label in labels]\n",
    "\n",
    "texts_train = texts[:45000]\n",
    "labels_train = labels[:45000]\n",
    "\n",
    "texts_valid = texts[45000:]\n",
    "labels_valid = labels[45000:]\n",
    "\n",
    "start_time = time.time()\n",
    "train_dataset = CustomDataset(texts_train, labels_train, tokenizer)\n",
    "valid_dataset = CustomDataset(texts_valid, labels_valid, tokenizer)\n",
    "print(\"Dataset Conversion Done!!\")\n",
    "print(\"Time Taken = \", (time.time() - start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHX1qodi5wTa"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-05\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "4kVCZMx785L1",
    "outputId": "237a2336-681d-4898-e7d3-3e37064f89e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train batches =  704\n",
      "Total valid batches =  79\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, shuffle=False, batch_size=BATCH_SIZE)\n",
    "print(\"Total train batches = \", len(train_loader))\n",
    "print(\"Total valid batches = \", len(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nPZpPFc597Iw",
    "outputId": "468d43b2-a9ce-4a08-d1b8-11248245e29f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters =  66956546\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification(config).to(device)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total Parameters = \", pytorch_total_params)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "colab_type": "code",
    "id": "fyNIlFkY-BRX",
    "outputId": "724bbcd1-1407-47bb-ecdb-184af9f1a45d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00001 || Batch: 00000 || Loss: 0.689\n",
      "Epoch: 00001 || Batch: 00100 || Loss: 0.717\n",
      "Epoch: 00001 || Batch: 00200 || Loss: 0.704\n",
      "Epoch: 00001 || Batch: 00300 || Loss: 0.696\n",
      "Epoch: 00001 || Batch: 00400 || Loss: 0.653\n",
      "Epoch: 00001 || Batch: 00500 || Loss: 0.663\n",
      "Epoch: 00001 || Batch: 00600 || Loss: 0.670\n",
      "Epoch: 00001 || Batch: 00700 || Loss: 0.684\n",
      "Train Accuracy =  tensor(56.7000, device='cuda:0')\n",
      "Valid Accuracy =  tensor(55.1000, device='cuda:0')\n",
      "Elapsed Time:  5.742435467243195\n",
      "Epoch: 00002 || Batch: 00000 || Loss: 0.640\n",
      "Epoch: 00002 || Batch: 00100 || Loss: 0.754\n",
      "Epoch: 00002 || Batch: 00200 || Loss: 0.676\n",
      "Epoch: 00002 || Batch: 00300 || Loss: 0.677\n",
      "Epoch: 00002 || Batch: 00400 || Loss: 0.651\n",
      "Epoch: 00002 || Batch: 00500 || Loss: 0.643\n",
      "Epoch: 00002 || Batch: 00600 || Loss: 0.649\n",
      "Epoch: 00002 || Batch: 00700 || Loss: 0.653\n",
      "Train Accuracy =  tensor(63.5356, device='cuda:0')\n",
      "Valid Accuracy =  tensor(57.5600, device='cuda:0')\n",
      "Elapsed Time:  11.487717839082082\n",
      "Epoch: 00003 || Batch: 00000 || Loss: 0.672\n",
      "Epoch: 00003 || Batch: 00100 || Loss: 0.616\n",
      "Epoch: 00003 || Batch: 00200 || Loss: 0.664\n",
      "Epoch: 00003 || Batch: 00300 || Loss: 0.719\n",
      "Epoch: 00003 || Batch: 00400 || Loss: 0.654\n",
      "Epoch: 00003 || Batch: 00500 || Loss: 0.665\n",
      "Epoch: 00003 || Batch: 00600 || Loss: 0.679\n",
      "Epoch: 00003 || Batch: 00700 || Loss: 0.637\n",
      "Train Accuracy =  tensor(63.0378, device='cuda:0')\n",
      "Valid Accuracy =  tensor(57.6400, device='cuda:0')\n",
      "Elapsed Time:  17.235373000303905\n",
      "Epoch: 00004 || Batch: 00000 || Loss: 0.647\n",
      "Epoch: 00004 || Batch: 00100 || Loss: 0.583\n",
      "Epoch: 00004 || Batch: 00200 || Loss: 0.548\n",
      "Epoch: 00004 || Batch: 00300 || Loss: 0.631\n",
      "Epoch: 00004 || Batch: 00400 || Loss: 0.628\n",
      "Epoch: 00004 || Batch: 00500 || Loss: 0.591\n",
      "Epoch: 00004 || Batch: 00600 || Loss: 0.580\n",
      "Epoch: 00004 || Batch: 00700 || Loss: 0.630\n",
      "Train Accuracy =  tensor(68.5889, device='cuda:0')\n",
      "Valid Accuracy =  tensor(59.3000, device='cuda:0')\n",
      "Elapsed Time:  22.984306359291075\n",
      "Epoch: 00005 || Batch: 00000 || Loss: 0.704\n",
      "Epoch: 00005 || Batch: 00100 || Loss: 0.639\n",
      "Epoch: 00005 || Batch: 00200 || Loss: 0.592\n",
      "Epoch: 00005 || Batch: 00300 || Loss: 0.603\n",
      "Epoch: 00005 || Batch: 00400 || Loss: 0.661\n",
      "Epoch: 00005 || Batch: 00500 || Loss: 0.583\n",
      "Epoch: 00005 || Batch: 00600 || Loss: 0.716\n",
      "Epoch: 00005 || Batch: 00700 || Loss: 0.691\n",
      "Train Accuracy =  tensor(70.0178, device='cuda:0')\n",
      "Valid Accuracy =  tensor(60.1400, device='cuda:0')\n",
      "Elapsed Time:  28.73652245203654\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    model.eval()\n",
    "    for idx, sample in enumerate(data_loader):\n",
    "        ids = sample['ids'].to(device)\n",
    "        mask = sample['mask'].to(device)\n",
    "        target = sample['target'].to(device)\n",
    "\n",
    "        output = model(input_ids=ids, attention_mask=mask)\n",
    "        logits = output[0]\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += target.size(0)\n",
    "        correct_pred += (predicted_labels.unsqueeze(1) == target).sum()\n",
    "    return correct_pred.float()/num_examples*100\n",
    "        \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for idx, sample in enumerate(train_loader):\n",
    "        ids = sample['ids'].to(device)\n",
    "        mask = sample['mask'].to(device)\n",
    "        target = sample['target'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_ids=ids, attention_mask=mask, labels=target, return_dict=True)\n",
    "        loss = output[0]\n",
    "\n",
    "        # LOGGING\n",
    "        if idx % 100 == 0:\n",
    "            print(\"Epoch: %05d || Batch: %05d || Loss: %.3f\" % (epoch+1, idx, loss.item()))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        train_acc = compute_accuracy(model, train_loader, device)\n",
    "        valid_acc = compute_accuracy(model, valid_loader, device)\n",
    "\n",
    "        print(\"Train Accuracy = \", train_acc)\n",
    "        print(\"Valid Accuracy = \", valid_acc)\n",
    "\n",
    "    elapsed_time = (time.time() - start_time) / 60\n",
    "    print(\"Elapsed Time: \", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3gRZ9tU2-O_j"
   },
   "outputs": [],
   "source": [
    "# Further improvements can be done!!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "test_sample_BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "18ac6ad4fd2f485aa244aaf7508129d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2817a859bd674b3cbcee99c379a5d976": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18ac6ad4fd2f485aa244aaf7508129d5",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c324ce2d0b674faaa5459d39642cd226",
      "value": 231508
     }
    },
    "9191a1268f1a468d99cb0724f084ae20": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d2f8a72ca3c4cef855020daf4759d23": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b26c7cd3be024779980b4f5c925acdda": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c324ce2d0b674faaa5459d39642cd226": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fa0cb2dd551a44e18b2068a3f6f8851a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2817a859bd674b3cbcee99c379a5d976",
       "IPY_MODEL_fa0f7a7fe2d3417fa63daeaecf93128e"
      ],
      "layout": "IPY_MODEL_9d2f8a72ca3c4cef855020daf4759d23"
     }
    },
    "fa0f7a7fe2d3417fa63daeaecf93128e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b26c7cd3be024779980b4f5c925acdda",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9191a1268f1a468d99cb0724f084ae20",
      "value": " 232k/232k [00:00&lt;00:00, 385kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
