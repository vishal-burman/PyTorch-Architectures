{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_sample_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa0cb2dd551a44e18b2068a3f6f8851a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d2f8a72ca3c4cef855020daf4759d23",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2817a859bd674b3cbcee99c379a5d976",
              "IPY_MODEL_fa0f7a7fe2d3417fa63daeaecf93128e"
            ]
          }
        },
        "9d2f8a72ca3c4cef855020daf4759d23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2817a859bd674b3cbcee99c379a5d976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c324ce2d0b674faaa5459d39642cd226",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18ac6ad4fd2f485aa244aaf7508129d5"
          }
        },
        "fa0f7a7fe2d3417fa63daeaecf93128e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9191a1268f1a468d99cb0724f084ae20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 385kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b26c7cd3be024779980b4f5c925acdda"
          }
        },
        "c324ce2d0b674faaa5459d39642cd226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18ac6ad4fd2f485aa244aaf7508129d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9191a1268f1a468d99cb0724f084ae20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b26c7cd3be024779980b4f5c925acdda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "086whqMNZoOW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "486f8a66-7288-47ea-adcc-9eb0fa283522"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Sep  8 01:49:00 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGjacpdN4pe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-MUtCHC4wYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "e7f1854d-e13a-4784-a0bd-0a5e515d33a9"
      },
      "source": [
        "#! rm -rf PyTorch-Architectures/\n",
        "! git clone https://github.com/vishal-burman/PyTorch-Architectures.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorch-Architectures'...\n",
            "remote: Enumerating objects: 242, done.\u001b[K\n",
            "remote: Counting objects: 100% (242/242), done.\u001b[K\n",
            "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
            "remote: Total 242 (delta 154), reused 150 (delta 78), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (242/242), 57.22 KiB | 332.00 KiB/s, done.\n",
            "Resolving deltas: 100% (154/154), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQgMhF8E5RAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp /content/drive/'My Drive'/dataset.csv ."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GnP4BTA8DD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp dataset.csv PyTorch-Architectures/modeling_bert/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRlSBeNM8aEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bcb811f-be2a-429b-dd0f-61d6c82a69ff"
      },
      "source": [
        "%cd PyTorch-Architectures/modeling_bert/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PyTorch-Architectures/modeling_bert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_6mzxsj5b5p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "fa0cb2dd551a44e18b2068a3f6f8851a",
            "9d2f8a72ca3c4cef855020daf4759d23",
            "2817a859bd674b3cbcee99c379a5d976",
            "fa0f7a7fe2d3417fa63daeaecf93128e",
            "c324ce2d0b674faaa5459d39642cd226",
            "18ac6ad4fd2f485aa244aaf7508129d5",
            "9191a1268f1a468d99cb0724f084ae20",
            "b26c7cd3be024779980b4f5c925acdda"
          ]
        },
        "outputId": "f06c9f74-065d-4d6d-d8eb-d10926c030eb"
      },
      "source": [
        "import time\n",
        "import csv\n",
        "import sys\n",
        "import pdb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from model import BertForSequenceClassification\n",
        "from transformers import BertTokenizer\n",
        "from config_bert import BertConfig\n",
        "config = BertConfig()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa0cb2dd551a44e18b2068a3f6f8851a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7veKShFA7uuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########################################\n",
        "# Sample data code\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.train_list = []\n",
        "        self.label_list = []\n",
        "        self.build()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ids = self.train_list[index]['input_ids']\n",
        "        mask = self.train_list[index]['attention_mask']\n",
        "        target = self.label_list[index]\n",
        "\n",
        "        return{\n",
        "                'ids': torch.tensor(ids, dtype=torch.long),\n",
        "                'mask': torch.tensor(ids, dtype=torch.long),\n",
        "                'target': torch.tensor(target, dtype=torch.long).unsqueeze(0)\n",
        "                }\n",
        "\n",
        "    def build(self):\n",
        "        for t, l in zip(self.texts, self.labels):\n",
        "            self.train_list.append(tokenizer(t, max_length=128, pad_to_max_length=True, truncation=True))\n",
        "            self.label_list.append(l)\n",
        "##########################################\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RVFP3DJ5pPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "d9344be9-dd56-437d-d402-b344b342d79a"
      },
      "source": [
        "texts = []\n",
        "labels = []\n",
        "with open(\"dataset.csv\", \"r\") as file_1:\n",
        "    reader = csv.reader(file_1)\n",
        "    for line in reader:\n",
        "        texts.append(line[0].strip())\n",
        "        labels.append(line[1].strip())\n",
        "\n",
        "texts = texts[1:]\n",
        "labels = labels[1:]\n",
        "\n",
        "labels = [1 if label == \"positive\" else 0 for label in labels]\n",
        "\n",
        "texts_train = texts[:45000]\n",
        "labels_train = labels[:45000]\n",
        "\n",
        "texts_valid = texts[45000:]\n",
        "labels_valid = labels[45000:]\n",
        "\n",
        "start_time = time.time()\n",
        "train_dataset = CustomDataset(texts_train, labels_train, tokenizer)\n",
        "valid_dataset = CustomDataset(texts_valid, labels_valid, tokenizer)\n",
        "print(\"Dataset Conversion Done!!\")\n",
        "print(\"Time Taken = \", (time.time() - start_time)/60)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset Conversion Done!!\n",
            "Time Taken =  3.045784366130829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHX1qodi5wTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 1e-05\n",
        "EPOCHS = 5"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kVCZMx785L1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "237a2336-681d-4898-e7d3-3e37064f89e0"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
        "valid_loader = DataLoader(dataset=valid_dataset, shuffle=False, batch_size=BATCH_SIZE)\n",
        "print(\"Total train batches = \", len(train_loader))\n",
        "print(\"Total valid batches = \", len(valid_loader))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total train batches =  704\n",
            "Total valid batches =  79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPZpPFc597Iw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "468d43b2-a9ce-4a08-d1b8-11248245e29f"
      },
      "source": [
        "model = BertForSequenceClassification(config).to(device)\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"Total Parameters = \", pytorch_total_params)\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Parameters =  66956546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyNIlFkY-BRX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "724bbcd1-1407-47bb-ecdb-184af9f1a45d"
      },
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    model.eval()\n",
        "    for idx, sample in enumerate(data_loader):\n",
        "        ids = sample['ids'].to(device)\n",
        "        mask = sample['mask'].to(device)\n",
        "        target = sample['target'].to(device)\n",
        "\n",
        "        output = model(input_ids=ids, attention_mask=mask)\n",
        "        logits = output[0]\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        _, predicted_labels = torch.max(probas, 1)\n",
        "        num_examples += target.size(0)\n",
        "        correct_pred += (predicted_labels.unsqueeze(1) == target).sum()\n",
        "    return correct_pred.float()/num_examples*100\n",
        "        \n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    for idx, sample in enumerate(train_loader):\n",
        "        ids = sample['ids'].to(device)\n",
        "        mask = sample['mask'].to(device)\n",
        "        target = sample['target'].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(input_ids=ids, attention_mask=mask, labels=target, return_dict=True)\n",
        "        loss = output[0]\n",
        "\n",
        "        # LOGGING\n",
        "        if idx % 100 == 0:\n",
        "            print(\"Epoch: %05d || Batch: %05d || Loss: %.3f\" % (epoch+1, idx, loss.item()))\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False):\n",
        "\n",
        "        train_acc = compute_accuracy(model, train_loader, device)\n",
        "        valid_acc = compute_accuracy(model, valid_loader, device)\n",
        "\n",
        "        print(\"Train Accuracy = \", train_acc)\n",
        "        print(\"Valid Accuracy = \", valid_acc)\n",
        "\n",
        "    elapsed_time = (time.time() - start_time) / 60\n",
        "    print(\"Elapsed Time: \", elapsed_time)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 00001 || Batch: 00000 || Loss: 0.689\n",
            "Epoch: 00001 || Batch: 00100 || Loss: 0.717\n",
            "Epoch: 00001 || Batch: 00200 || Loss: 0.704\n",
            "Epoch: 00001 || Batch: 00300 || Loss: 0.696\n",
            "Epoch: 00001 || Batch: 00400 || Loss: 0.653\n",
            "Epoch: 00001 || Batch: 00500 || Loss: 0.663\n",
            "Epoch: 00001 || Batch: 00600 || Loss: 0.670\n",
            "Epoch: 00001 || Batch: 00700 || Loss: 0.684\n",
            "Train Accuracy =  tensor(56.7000, device='cuda:0')\n",
            "Valid Accuracy =  tensor(55.1000, device='cuda:0')\n",
            "Elapsed Time:  5.742435467243195\n",
            "Epoch: 00002 || Batch: 00000 || Loss: 0.640\n",
            "Epoch: 00002 || Batch: 00100 || Loss: 0.754\n",
            "Epoch: 00002 || Batch: 00200 || Loss: 0.676\n",
            "Epoch: 00002 || Batch: 00300 || Loss: 0.677\n",
            "Epoch: 00002 || Batch: 00400 || Loss: 0.651\n",
            "Epoch: 00002 || Batch: 00500 || Loss: 0.643\n",
            "Epoch: 00002 || Batch: 00600 || Loss: 0.649\n",
            "Epoch: 00002 || Batch: 00700 || Loss: 0.653\n",
            "Train Accuracy =  tensor(63.5356, device='cuda:0')\n",
            "Valid Accuracy =  tensor(57.5600, device='cuda:0')\n",
            "Elapsed Time:  11.487717839082082\n",
            "Epoch: 00003 || Batch: 00000 || Loss: 0.672\n",
            "Epoch: 00003 || Batch: 00100 || Loss: 0.616\n",
            "Epoch: 00003 || Batch: 00200 || Loss: 0.664\n",
            "Epoch: 00003 || Batch: 00300 || Loss: 0.719\n",
            "Epoch: 00003 || Batch: 00400 || Loss: 0.654\n",
            "Epoch: 00003 || Batch: 00500 || Loss: 0.665\n",
            "Epoch: 00003 || Batch: 00600 || Loss: 0.679\n",
            "Epoch: 00003 || Batch: 00700 || Loss: 0.637\n",
            "Train Accuracy =  tensor(63.0378, device='cuda:0')\n",
            "Valid Accuracy =  tensor(57.6400, device='cuda:0')\n",
            "Elapsed Time:  17.235373000303905\n",
            "Epoch: 00004 || Batch: 00000 || Loss: 0.647\n",
            "Epoch: 00004 || Batch: 00100 || Loss: 0.583\n",
            "Epoch: 00004 || Batch: 00200 || Loss: 0.548\n",
            "Epoch: 00004 || Batch: 00300 || Loss: 0.631\n",
            "Epoch: 00004 || Batch: 00400 || Loss: 0.628\n",
            "Epoch: 00004 || Batch: 00500 || Loss: 0.591\n",
            "Epoch: 00004 || Batch: 00600 || Loss: 0.580\n",
            "Epoch: 00004 || Batch: 00700 || Loss: 0.630\n",
            "Train Accuracy =  tensor(68.5889, device='cuda:0')\n",
            "Valid Accuracy =  tensor(59.3000, device='cuda:0')\n",
            "Elapsed Time:  22.984306359291075\n",
            "Epoch: 00005 || Batch: 00000 || Loss: 0.704\n",
            "Epoch: 00005 || Batch: 00100 || Loss: 0.639\n",
            "Epoch: 00005 || Batch: 00200 || Loss: 0.592\n",
            "Epoch: 00005 || Batch: 00300 || Loss: 0.603\n",
            "Epoch: 00005 || Batch: 00400 || Loss: 0.661\n",
            "Epoch: 00005 || Batch: 00500 || Loss: 0.583\n",
            "Epoch: 00005 || Batch: 00600 || Loss: 0.716\n",
            "Epoch: 00005 || Batch: 00700 || Loss: 0.691\n",
            "Train Accuracy =  tensor(70.0178, device='cuda:0')\n",
            "Valid Accuracy =  tensor(60.1400, device='cuda:0')\n",
            "Elapsed Time:  28.73652245203654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gRZ9tU2-O_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Further improvements can be done!!"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}